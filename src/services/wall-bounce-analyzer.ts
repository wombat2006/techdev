/**
 * å£æ‰“ã¡åˆ†æã‚·ã‚¹ãƒ†ãƒ  - è¤‡æ•°LLMã«ã‚ˆã‚‹å”èª¿åˆ†æ
 * å¿…é ˆè¦ä»¶: ã™ã¹ã¦ã®ã‚¯ã‚¨ãƒªã§æœ€ä½2ã¤ã®LLMã«ã‚ˆã‚‹åˆ†æã‚’å®Ÿè¡Œ
 */

import { EventEmitter } from 'events';
import { logger } from '../utils/logger';
import { config } from '../config/environment';
import { createCodexGPT5Provider } from './codex-gpt5-provider';


// Load provider configuration from external file
import * as fs from 'fs';
import * as path from 'path';

interface ProviderConfig {
  key: string;
  name: string;
  model: string;
  modelArgs?: Record<string, any>;
  tier: number;
  capabilities: string[];
  invocationType: 'gemini' | 'gpt5' | 'claude';
  role?: 'default-aggregator' | 'complex-aggregator';
}

interface LLMProvidersConfig {
  providers: ProviderConfig[];
  aggregatorSelection: {
    defaultAggregator: string;
    complexAggregator: string;
    complexityThreshold: number;
    complexityIndicators: {
      keywords: string[];
      japaneseKeywords: string[];
      promptLengthThreshold: number;
      questionMarkThreshold: number;
    };
  };
  taskTypeMapping: Record<string, string>;
}

let providersConfig: LLMProvidersConfig;
try {
  const configPath = path.join(__dirname, '../config/llm-providers.json');
  providersConfig = JSON.parse(fs.readFileSync(configPath, 'utf-8'));
} catch (error) {
  logger.error('Failed to load LLM providers config', { error });
  throw new Error('LLM providers configuration is required');
}

const DEFAULT_AGGREGATOR_PROVIDER = providersConfig.aggregatorSelection.defaultAggregator;
const COMPLEX_AGGREGATOR_PROVIDER = providersConfig.aggregatorSelection.complexAggregator;

const PROVIDER_GUIDANCE: Record<string, { parallel?: string[]; sequential?: string }> = {
  'gemini-2.5-pro': {
    parallel: [
      'æœ€æ–°ã®å…¬é–‹æƒ…å ±ã‚„æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¸ã¾ãˆã€å…¨ä½“ã®èƒŒæ™¯ãƒ»èª²é¡Œãƒ»å½±éŸ¿ã‚’æ•´ç†ã—ã¦ãã ã•ã„ã€‚',
      'æ—¥æœ¬èªã§ã€ç®‡æ¡æ›¸ãã¨çŸ­ã„è£œè¶³èª¬æ˜ã‚’çµ„ã¿åˆã‚ã›ã¦ãã ã•ã„ã€‚'
    ],
    sequential: 'ã“ã‚Œã¾ã§ã«å¾—ã‚‰ã‚ŒãŸæ´å¯Ÿã‚’è£œè¶³ã—ã€èƒŒæ™¯æƒ…å ±ã‚„æ½œåœ¨çš„ãƒªã‚¹ã‚¯ã‚’æ•´ç†ã—ã¦ãã ã•ã„ã€‚'
  },
  'gpt-5-codex': {
    parallel: [
      'è¦æ±‚ä»•æ§˜: å®Ÿè£…æ‰‹é †ã‚’1-5ã‚¹ãƒ†ãƒƒãƒ—ã§æ˜ç¢ºã«ç¤ºã—ã€å„ã‚¹ãƒ†ãƒƒãƒ—ã«å…·ä½“çš„ãªã‚³ãƒ¼ãƒ‰ä¾‹ã‚’å«ã‚ã¦ãã ã•ã„ã€‚',
      'åˆ¶ç´„: ç‰¹å®šã•ã‚ŒãŸãƒªã‚¹ã‚¯ã¯é‡è¦åº¦é †ï¼ˆé«˜/ä¸­/ä½ï¼‰ã§åˆ†é¡ã—ã€å„æ”¹å–„æ¡ˆã¯å®Ÿè£…é›£æ˜“åº¦ã‚’ä»˜è¨˜ã—ã¦ãã ã•ã„ã€‚'
    ],
    sequential: 'åˆ¶ç´„: æ—¢å‡ºåˆ†æã¨ã®çŸ›ç›¾ã‚’é¿ã‘ã€æ–°è¦å®Ÿè£…è¦ç´ ã®ã¿è©³è¿°ã—ã¦ãã ã•ã„ã€‚æœªè§£æ±ºã®æŠ€è¡“èª²é¡ŒãŒã‚ã‚Œã°å…·ä½“çš„ãªèª¿æŸ»æ–¹é‡ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚'
  },
  'gpt-5': {
    parallel: [
      'è¦æ±‚ä»•æ§˜: è¨­è¨ˆé¸æŠè‚¢ã‚’æœ€å¤§3ã¤ã¾ã§ã«çµã‚Šã€å„é¸æŠè‚¢ã®ã‚³ã‚¹ãƒˆãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ€§ã‚’æ•°å€¤ã¾ãŸã¯ãƒ©ãƒ³ã‚¯è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚',
      'åˆ¶ç´„: çµè«–ã¯æ˜ç¢ºãªæ¨å¥¨äº‹é …ï¼ˆæ¡ç”¨/éæ¡ç”¨ï¼‰ã¨æ ¹æ‹ ã‚’3ã¤ã¾ã§ã§ç¤ºã—ã¦ãã ã•ã„ã€‚'
    ],
    sequential: 'åˆ¶ç´„: æ—¢å‡ºåˆ†æã®è¨­è¨ˆæ±ºå®šã¨æ•´åˆæ€§ã‚’ä¿ã¡ã€æ–°ãŸãªæ„æ€æ±ºå®šè¦ç´ ã®ã¿æç¤ºã—ã¦ãã ã•ã„ã€‚é•·æœŸå½±éŸ¿ã¯å®šé‡çš„ãƒªã‚¹ã‚¯è©•ä¾¡ã‚’å«ã‚ã¦ãã ã•ã„ã€‚'
  },
  'sonnet-4': {
    parallel: [
      'äººçš„ãƒ»é‹ç”¨çš„ãªè¦³ç‚¹ã‹ã‚‰ã®å½±éŸ¿ã‚„ãƒªã‚¹ã‚¯ã€é–¢ä¿‚è€…ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒã‚¤ãƒ³ãƒˆã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚',
      'ç°¡æ½”ãªã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚’æ·»ãˆã¦ãã ã•ã„ã€‚'
    ],
    sequential: 'æ—¢å‡ºã®åˆ†æã‚’è¸ã¾ãˆã€é‹ç”¨æ‰‹é †ã‚„ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¦³ç‚¹ã§ã®æ¨å¥¨äº‹é …ã‚’è£œè¶³ã—ã¦ãã ã•ã„ã€‚'
  }
};

const AGGREGATOR_INSTRUCTIONS = [
  'ä»¥ä¸‹ã®å„LLMå›ç­”ã‚’çµ±åˆã—ã€çŸ›ç›¾ãŒã‚ã‚Œã°æ•´åˆã•ã›ã¦ãã ã•ã„ã€‚',
  'é‡è¤‡å†…å®¹ã¯çµ±åˆã—ã€æœ€çµ‚çš„ãªæ¨å¥¨è¡Œå‹•ãƒ»ç•™æ„ç‚¹ãƒ»ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã‚’æ˜ç¢ºã«ã—ã¦ãã ã•ã„ã€‚',
  'ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã¯æ—¥æœ¬èªã§ã€è¦ç´„â†’æ¨å¥¨â†’ãƒªã‚¹ã‚¯/ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã®é †ã§æ§‹æˆã—ã¦ãã ã•ã„ã€‚'
];

const META_PROMPT_TEMPLATE = `
ã‚ãªãŸã¯å£æ‰“ã¡åˆ†æã‚·ã‚¹ãƒ†ãƒ ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚
ä»¥ä¸‹ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’åˆ†æã—ã€æ”¹å–„æ¡ˆã‚’æç¤ºã—ã¦ãã ã•ã„ï¼š

ç¾åœ¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {current_prompt}
å¯¾è±¡ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {provider_name}
åˆ†æã‚¿ã‚¹ã‚¯: {task_type}

æœ€é©åŒ–è¦³ç‚¹:
1. æ›–æ˜§æ€§ã®é™¤å»: è§£é‡ˆãŒåˆ†ã‹ã‚Œã‚‹è¡¨ç¾ã‚’ç‰¹å®šã—ä¿®æ­£æ¡ˆã‚’æç¤º
2. åˆ¶ç´„ã®æ˜ç¢ºåŒ–: å…·ä½“çš„ãªå‡ºåŠ›è¦ä»¶ã¨åˆ¶é™ã‚’å®šç¾©
3. åŠ¹ç‡æ€§å‘ä¸Š: ä¸è¦ãªèª¬æ˜ã‚’å‰Šé™¤ã—ã€æ ¸å¿ƒçš„æŒ‡ç¤ºã«é›†ç´„
4. æ•´åˆæ€§ç¢ºä¿: ä»–ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã¨ã®å½¹å‰²åˆ†æ‹…ã‚’æ˜ç¢ºåŒ–

æ”¹å–„æ¡ˆã‚’ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
- å•é¡Œç‚¹: [å…·ä½“çš„ãªå•é¡Œ]
- ä¿®æ­£æ¡ˆ: [æ”¹å–„ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ]
- æœŸå¾…åŠ¹æœ: [æ”¹å–„ã«ã‚ˆã‚‹åŠ¹æœ]
`;

export interface LLMProvider {
  name: string;
  model: string;
  invoke: (prompt: string, options?: any) => Promise<LLMResponse>; // eslint-disable-line @typescript-eslint/no-unused-vars, no-unused-vars
}

export interface LLMResponse {
  content: string;
  confidence: number;
  reasoning: string;
  cost: number;
  tokens: {
    input: number;
    output: number;
    total?: number;
  };
  provider?: string;
}

export interface WallBounceResult {
  consensus: {
    content: string;
    confidence: number;
    reasoning: string;
  };
  llm_votes: Array<{
    provider: string;
    model: string;
    response: LLMResponse;
    agreement_score: number;
  }>;
  total_cost: number;
  processing_time_ms: number;
  debug: {
    wall_bounce_verified: boolean;
    providers_used: string[];
    tier_escalated: boolean;
    provider_errors?: string[];
    depth_executed?: number;
  };
  // æ–°ã—ã„è©³ç´°ãƒ•ãƒ­ãƒ¼æƒ…å ±
  flow_details?: WallBounceFlowDetails;
}

export interface WallBounceFlowDetails {
  user_query: {
    original_prompt: string;
    timestamp: string;
    options: ExecuteOptions;
  };
  llm_interactions: Array<{
    step: number;
    provider: string;
    input_prompt: string;
    output_response: string;
    confidence: number;
    processing_time_ms: number;
    timestamp: string;
    accumulated_context?: string;
  }>;
  aggregation: {
    input_responses: Array<{
      provider: string;
      content: string;
      confidence: number;
    }>;
    aggregator_prompt: string;
    final_response: string;
    timestamp: string;
  };
}

interface ExecuteOptions {
  taskType?: 'basic' | 'premium' | 'critical';
  minProviders?: number;
  maxProviders?: number;
  mode?: 'parallel' | 'sequential';
  depth?: number; // 3-5: ã‚·ãƒªã‚¢ãƒ«ãƒ¢ãƒ¼ãƒ‰æ™‚ã®wall-bounceæ·±åº¦
  
  // Streaming callbacks for real-time thinking process display
  onThinking?: (provider: string, step: string, content: string) => void;
  onProviderResponse?: (provider: string, response: string) => void;
  onConsensusUpdate?: (score: number) => void;
}

export class WallBounceAnalyzer extends EventEmitter {
  private providers: Map<string, LLMProvider> = new Map();
  private providerOrder: string[] = [];

  constructor() {
    super();
    this.initializeProviders();
  }

  private initializeProviders() {
    // é«˜å“è³ªLLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ã¿ã«é™å®š
    // "Gemini-2.5-pro", "GPT-5-codex", "GPT-5", "Sonnet4", "Opus4.1"

    // Tier 1a: Gemini 2.5 Pro (CLIå¿…é ˆ - æŠ€è¡“çš„ã‚¯ã‚¨ãƒªç”¨)
    this.providers.set('gemini-2.5-pro', {
      name: 'Gemini-2.5-pro',
      model: 'gemini-2.5-pro',
      invoke: this.invokeGemini.bind(this) // CLIçµŒç”±ã®ã¿
    });
    this.providerOrder.push('gemini-2.5-pro');

    // Tier 1b: Gemini 2.5 Flash (CLIå¿…é ˆ - ã‚·ãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒªç”¨è»½é‡ãƒ¢ãƒ‡ãƒ«)
    this.providers.set('gemini-2.5-flash', {
      name: 'Gemini-2.5-flash',
      model: 'gemini-2.5-flash',
      invoke: this.invokeGeminiFlash.bind(this) // CLIçµŒç”±ã®ã¿
    });
    this.providerOrder.push('gemini-2.5-flash');

    // Tier 2: GPT-5 Codex via CLI (ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç‰¹åŒ– - CLIå¿…é ˆ)
    this.providers.set('gpt-5-codex', {
      name: 'GPT-5-codex',
      model: 'gpt-5-codex',
      invoke: this.invokeGPT5.bind(this) // CLIçµŒç”±ã®ã¿
    });
    this.providerOrder.push('gpt-5-codex');

    // Tier 2b: GPT-5 General via CLI (æ±ç”¨ã‚¿ã‚¹ã‚¯ - CLIå¿…é ˆ)
    this.providers.set('gpt-5', {
      name: 'GPT-5',
      model: 'gpt-5',
      invoke: this.invokeGPT5.bind(this) // CLIçµŒç”±ã®ã¿
    });
    this.providerOrder.push('gpt-5');

    // Tier 3: Anthropic Sonnet 4 (å†…éƒ¨å‘¼ã³å‡ºã—ã®ã¿)
    this.providers.set('sonnet-4', {
      name: 'Sonnet4',
      model: 'claude-sonnet-4',
      invoke: this.invokeClaude.bind(this) // å†…éƒ¨å‘¼ã³å‡ºã—ã®ã¿ã€APIç¦æ­¢
    });
    this.providerOrder.push('sonnet-4');

    // Tier 3.5: Anthropic Sonnet 4.5 (å†…éƒ¨å‘¼ã³å‡ºã—ã®ã¿ - Default Aggregator)
    this.providers.set('sonnet-4.5', {
      name: 'Sonnet4.5',
      model: 'claude-sonnet-4-5-20250929',
      invoke: this.invokeClaude.bind(this) // å†…éƒ¨å‘¼ã³å‡ºã—ã®ã¿ã€APIç¦æ­¢
    });
    this.providerOrder.push('sonnet-4.5');

    // Tier 4: Anthropic Opus 4.1 (å†…éƒ¨å‘¼ã³å‡ºã—ã®ã¿ - Complex Queries Aggregator)
    this.providers.set('opus-4.1', {
      name: 'Opus4.1',
      model: 'claude-opus-4.1',
      invoke: this.invokeClaude.bind(this) // å†…éƒ¨å‘¼ã³å‡ºã—ã®ã¿ã€APIç¦æ­¢
    });
    this.providerOrder.push('opus-4.1');

    logger.info('ğŸš€ Wall-Bounce ProvidersåˆæœŸåŒ–å®Œäº†ï¼ˆé«˜å“è³ªãƒ¢ãƒ‡ãƒ«ã®ã¿ï¼‰', {
      total_providers: this.providers.size,
      gemini_pro_providers: 1, // Gemini-2.5-pro only
      gpt5_providers: 2, // GPT-5-codex + GPT-5
      anthropic_providers: 2, // Sonnet4 + Opus4.1
      excluded_models: ['gemini-2.5-flash', 'lower-tier-models'],
      enforced_restrictions: {
        openai_gemini: 'CLI_ONLY',
        anthropic: 'INTERNAL_ONLY',
        quality_tier: 'HIGH_ONLY'
      }
    });
  }

  /**
   * Google Gemini APIçµŒç”±ã§ã®å®Ÿè¡Œ
   */
  /**
   * ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒªã®æ€§è³ªã‚’åˆ¤å®š
   */
  private isSimpleQuery(query: string): boolean {
    const trimmedQuery = query.trim();
    const lowerQuery = trimmedQuery.toLowerCase();
    
    // æœ€ä½æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯ï¼ˆ1-2æ–‡å­—ã®å˜èªã¯é™¤å¤–ï¼‰
    if (trimmedQuery.length < 3) {
      return false;
    }
    
    // æŠ€è¡“ç”¨èªãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆ - ã“ã‚Œã‚‰ã‚’å«ã‚€å ´åˆã¯æŠ€è¡“çš„ã‚¯ã‚¨ãƒª
    const technicalKeywords = [
      'å®Ÿè£…', 'è¨­è¨ˆ', 'ã‚³ãƒ¼ãƒ‰', 'API', 'ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ', 
      'ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£', 'ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹', 'ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹',
      'æœ€é©åŒ–', 'ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹', 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£', 'TypeScript',
      'JavaScript', 'Python', 'ã‚·ã‚¹ãƒ†ãƒ ', 'é–‹ç™º', 'ãƒ—ãƒ­ã‚°ãƒ©ãƒ ',
      'ã‚«ãƒãƒ¬ãƒƒã‚¸', 'ãƒ¦ãƒ‹ãƒƒãƒˆ', 'çµ±åˆãƒ†ã‚¹ãƒˆ', 'E2E'
    ];
    
    // æŠ€è¡“ç”¨èªãŒå«ã¾ã‚Œã¦ã„ãŸã‚‰æŠ€è¡“çš„ã‚¯ã‚¨ãƒª
    if (technicalKeywords.some(keyword => lowerQuery.includes(keyword.toLowerCase()))) {
      return false;
    }
    
    // ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¯ã‚¨ãƒªã®ãƒ‘ã‚¿ãƒ¼ãƒ³
    const simplePatterns = [
      /^(hello|hi|hey|ã“ã‚“ã«ã¡ã¯|ãŠã¯ã‚ˆã†|ã“ã‚“ã°ã‚“ã¯)$/i,
      /^test$/i,
      /^(ãƒ†ã‚¹ãƒˆã®?è¿”äº‹|è¿”äº‹.*ãƒ†ã‚¹ãƒˆ)$/,
      /^(ok|okay|thanks?|ã‚ã‚ŠãŒã¨|ã‚µãƒ³ã‚¯ã‚¹)$/i,
      /^(ping|pong|echo)$/i,
      /^(ç¢ºèª|ãƒã‚§ãƒƒã‚¯|å‹•ä½œç¢ºèª)$/,
    ];
    
    // 20æ–‡å­—ä»¥ä¸‹ã§ã€ã‚·ãƒ³ãƒ—ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å³å¯†ãƒãƒƒãƒ
    if (trimmedQuery.length <= 20 && simplePatterns.some(pattern => pattern.test(trimmedQuery))) {
      return true;
    }
    
    // ã€Œã€œã‚’è¿”ã—ã¦ãã ã•ã„ã€ã€Œã€œã—ã¦ãã ã•ã„ã€ã®ã‚ˆã†ãªå˜ç´”ãªè¦æ±‚ï¼ˆæŠ€è¡“ç”¨èªãªã—ï¼‰
    const simpleRequestPatterns = [
      /^.{1,15}(ã‚’?è¿”ã—ã¦ãã ã•ã„|ã—ã¦ãã ã•ã„|ãŠé¡˜ã„ã—ã¾ã™)$/,
    ];
    
    if (trimmedQuery.length <= 25 && simpleRequestPatterns.some(pattern => pattern.test(trimmedQuery))) {
      return true;
    }
    
    return false;
  }

  private async executeGeminiCLI(
    prompt: string,
    version: '2.5-pro' | '2.5-flash'
  ): Promise<LLMResponse> {
    try {
      const { spawn } = require('child_process');

      // ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯buildProviderPrompt()ã§æ—¢ã«å®Œæˆã—ã¦ã„ã‚‹ã®ã§ãã®ã¾ã¾ä½¿ç”¨
      const systemPrompt = prompt;

      // ã‚»ã‚­ãƒ¥ã‚¢ãªspawnä½¿ç”¨ - stdinçµŒç”±ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ¸¡ã™
      const modelName = version === '2.5-pro' ? 'gemini-2.5-pro' : 'gemini-2.5-flash';
      const args = ['--model', modelName, '--output-format', 'json'];

      logger.info('ğŸ¤– Gemini CLIå®Ÿè¡Œé–‹å§‹ (stdinçµŒç”±)', {
        command: 'gemini',
        args: ['--model', modelName, '--output-format', 'json'],
        promptPreview: systemPrompt.substring(0, 500)
      });
      
      // ãƒ‡ãƒãƒƒã‚°: å®Ÿéš›ã«é€ä¿¡ã•ã‚Œã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ­ã‚°å‡ºåŠ›
      logger.info('=' + '='.repeat(79));
      logger.info(`ğŸ“¤ Gemini ${version} ã¸ã®å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:`);
      logger.info('=' + '='.repeat(79));
      logger.info(systemPrompt);
      logger.info('=' + '='.repeat(79));

      // ã‚»ã‚­ãƒ¥ã‚¢ãªPromiseãƒ™ãƒ¼ã‚¹spawnå®Ÿè¡Œ
      const { stdout, stderr } = await new Promise<{stdout: string, stderr: string}>((resolve, reject) => {
        const child = spawn('gemini', args, { 
        timeout: config.wallBounce.enableTimeout ? config.wallBounce.timeoutMs : undefined,
        stdio: ['pipe', 'pipe', 'pipe'], // stdinçµŒç”±ã§å…¥åŠ›
        env: { ...process.env }
      });
        
        // stdinçµŒç”±ã§ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é€ä¿¡
        child.stdin?.write(systemPrompt);
        child.stdin?.end();
        
        let stdout = '';
        let stderr = '';

        child.stdout?.on('data', (data: any) => {
          const chunk = data.toString();
          stdout += chunk;
          
          // Emit real-time streaming event for each chunk
          this.emit('provider:streaming', {
            provider: version === '2.5-pro' ? 'gemini-2.5-pro' : 'gemini-2.5-flash',
            chunk: chunk,
            timestamp: Date.now()
          });
        });

        child.stderr?.on('data', (data: any) => {
          stderr += data.toString();
        });

        child.on('close', (code: number | null) => {
          if (code === 0) {
            resolve({ stdout, stderr });
          } else {
            reject(new Error(`Gemini CLI exit code: ${code}, stderr: ${stderr}`));
          }
        });

        child.on('error', (error: any) => {
          reject(new Error(`Spawn error: ${error.message}`));
        });

        // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç„¡åŠ¹åŒ–
        // const timeout = setTimeout(() => {
        //   child.kill('SIGTERM');
        //   reject(new Error('Gemini CLI timeout'));
        // }, 300000);

        // clearTimeout(timeout); // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç„¡åŠ¹åŒ–
      });
      
      if (stderr && !stderr.includes('DeprecationWarning')) {
        logger.warn('âš ï¸ Gemini CLIè­¦å‘Š', { stderr });
      }
      
      const response = JSON.parse(stdout);
      const content = response.content || response.text || stdout;
      const displayLabel = version === '2.5-pro' ? 'Gemini 2.5 Pro CLI' : 'Gemini 2.5 Flash CLI';
      const cost = version === '2.5-pro' ? 0.002 : 0.001;
      
      return {
        content: `[${displayLabel}] ${content}`,
        confidence: 0.88,
        reasoning: `Google ${displayLabel}çµŒç”±ã§ã®é«˜å“è³ªåˆ†æï¼ˆã‚»ã‚­ãƒ¥ã‚¢å®Ÿè£…ï¼‰`,
        cost,
        tokens: { input: Math.ceil(prompt.length / 4), output: Math.ceil(content.length / 4) }
      };
    } catch (error) {
      logger.error('âŒ Gemini CLI execution failed (ã‚»ã‚­ãƒ¥ã‚¢å®Ÿè£…)', { 
        error: error instanceof Error ? error.message : String(error),
        stderr: (error as any).stderr || 'No stderr'
      });
      
      throw new Error(`Gemini CLI failed: ${error instanceof Error ? error.message : String(error)}`);
    }
  }

  /**
   * å£æ‰“ã¡åˆ†æã®å®Ÿè¡Œ - ãƒ¢ãƒ¼ãƒ‰ã«ã‚ˆã£ã¦ä¸¦åˆ—/é€æ¬¡ã‚’åˆ‡ã‚Šæ›¿ãˆ
   */
  /**
   * Claude CodeãŒè¤‡é›‘ã•ã‚’èªè­˜ã—ã¦é©åˆ‡ãªã‚¢ã‚°ãƒªã‚²ãƒ¼ã‚¿ãƒ¼ã‚’é¸æŠ
   * å›ºå®šæ–‡å­—åˆ—åˆ¤å®šã§ã¯ãªãã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹é€ ãƒ»æ„å›³ã‚’åˆ†æ
   */
  private async selectAggregatorByCognitiveAnalysis(
    prompt: string,
    taskType: 'basic' | 'premium' | 'critical' | 'simple'
  ): Promise<string> {
    const config = providersConfig.aggregatorSelection;
    
    // ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¯ã‚¨ãƒªã¯è»½é‡ã‚¢ã‚°ãƒªã‚²ãƒ¼ã‚¿ãƒ¼
    if (taskType === 'simple') {
      logger.info(`ğŸ¯ Simple query detected â†’ Using Sonnet 4.5 for fast aggregation`);
      return config.defaultAggregator; // Sonnet 4.5
    }
    
    // criticalã‚¿ã‚¹ã‚¯ã¯å¸¸ã«Opus 4.1
    if (taskType === 'critical' || providersConfig.taskTypeMapping[taskType]) {
      const mappedAggregator = providersConfig.taskTypeMapping[taskType];
      if (mappedAggregator) {
        logger.info(`ğŸ¯ Task type mapping: ${taskType} â†’ ${mappedAggregator}`);
        return mappedAggregator;
      }
    }

    // Claude Codeè‡ªèº«ãŒè¤‡é›‘ã•ã‚’èªè­˜
    // ä»¥ä¸‹ã®è¦ç´ ã‚’ç·åˆçš„ã«åˆ¤æ–­ï¼š
    // 1. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹é€ çš„è¤‡é›‘ã•ï¼ˆéšå±¤æ€§ã€ä¾å­˜é–¢ä¿‚ï¼‰
    // 2. æ±‚ã‚ã‚‰ã‚Œã‚‹æ€è€ƒã®æ·±ã•ï¼ˆåˆ†æãƒ¬ãƒ™ãƒ«ï¼‰
    // 3. è¤‡æ•°ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ã¾ãŸãŒã‚‹ã‹
    
    const structuralComplexity = this.analyzeStructuralComplexity(prompt);
    const cognitiveDepth = this.analyzeCognitiveDepth(prompt);
    const domainBreadth = this.analyzeDomainBreadth(prompt);
    
    const complexityScore = structuralComplexity + cognitiveDepth + domainBreadth;
    
    // ã‚¹ã‚³ã‚¢ãŒé«˜ã„å ´åˆã¯Opus 4.1ã‚’ä½¿ç”¨
    if (complexityScore >= 6) {
      logger.info(`ğŸ¯ High complexity detected (score: ${complexityScore}) â†’ ${config.complexAggregator}`, {
        structural: structuralComplexity,
        cognitive: cognitiveDepth,
        domain: domainBreadth
      });
      return config.complexAggregator;
    }
    
    // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯Sonnet 4
    logger.info(`ğŸ¯ Standard complexity (score: ${complexityScore}) â†’ ${config.defaultAggregator}`, {
      structural: structuralComplexity,
      cognitive: cognitiveDepth,
      domain: domainBreadth
    });
    return config.defaultAggregator;
  }

  /**
   * æ§‹é€ çš„è¤‡é›‘ã•ã®åˆ†æï¼ˆéšå±¤æ€§ã€ä¾å­˜é–¢ä¿‚ï¼‰
   */
  private analyzeStructuralComplexity(prompt: string): number {
    let score = 0;
    
    // é•·ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå¤šãã®æƒ…å ±ã‚’å«ã‚€ï¼‰
    if (prompt.length > 800) score += 2;
    else if (prompt.length > 400) score += 1;
    
    // ç®‡æ¡æ›¸ãã‚„ç•ªå·ä»˜ããƒªã‚¹ãƒˆï¼ˆæ§‹é€ åŒ–ã•ã‚ŒãŸè¦æ±‚ï¼‰
    const listPatterns = /(?:^|\n)\s*[-*â€¢]|\d+\./gm;
    const listCount = (prompt.match(listPatterns) || []).length;
    if (listCount > 5) score += 2;
    else if (listCount > 2) score += 1;
    
    // è¤‡æ•°ã®è³ªå•ï¼ˆå¤šé¢çš„ãªåˆ†æè¦æ±‚ï¼‰
    const questionCount = (prompt.match(/[ï¼Ÿ?]/g) || []).length;
    if (questionCount > 4) score += 2;
    else if (questionCount > 2) score += 1;
    
    return Math.min(score, 3); // æœ€å¤§3ç‚¹
  }

  /**
   * èªçŸ¥çš„æ·±ã•ã®åˆ†æï¼ˆæ±‚ã‚ã‚‰ã‚Œã‚‹æ€è€ƒãƒ¬ãƒ™ãƒ«ï¼‰
   */
  private analyzeCognitiveDepth(prompt: string): number {
    let score = 0;
    
    // ã€Œãªãœã€ã€Œã©ã®ã‚ˆã†ã«ã€ç³»ã®æ·±ã„æ€è€ƒã‚’è¦æ±‚
    if (/ãªãœ|why|ç†ç”±|æ ¹æ‹ |èƒŒæ™¯/i.test(prompt)) score += 1;
    if (/ã©ã®ã‚ˆã†ã«|how|æ–¹æ³•|æ‰‹é †|ãƒ—ãƒ­ã‚»ã‚¹/i.test(prompt)) score += 1;
    
    // æ¯”è¼ƒãƒ»è©•ä¾¡ã‚’è¦æ±‚
    if (/æ¯”è¼ƒ|compare|è©•ä¾¡|evaluate|ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•|trade-?off/i.test(prompt)) score += 2;
    
    // è¨­è¨ˆãƒ»ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¬ãƒ™ãƒ«ã®æ€è€ƒ
    if (/è¨­è¨ˆ|design|ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£|architecture|æ§‹é€ |structure/i.test(prompt)) score += 1;
    
    return Math.min(score, 3); // æœ€å¤§3ç‚¹
  }

  /**
   * ãƒ‰ãƒ¡ã‚¤ãƒ³ã®åºƒã•åˆ†æï¼ˆè¤‡æ•°é ˜åŸŸã«ã¾ãŸãŒã‚‹ã‹ï¼‰
   */
  private analyzeDomainBreadth(prompt: string): number {
    let score = 0;
    const domains: string[] = [];
    
    // æŠ€è¡“ãƒ‰ãƒ¡ã‚¤ãƒ³
    if (/ã‚³ãƒ¼ãƒ‰|code|å®Ÿè£…|implement|ãƒ—ãƒ­ã‚°ãƒ©ãƒ /i.test(prompt)) domains.push('tech');
    
    // ãƒ“ã‚¸ãƒã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³
    if (/ãƒ“ã‚¸ãƒã‚¹|business|æˆ¦ç•¥|strategy|ROI|ã‚³ã‚¹ãƒˆ/i.test(prompt)) domains.push('business');
    
    // ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ‰ãƒ¡ã‚¤ãƒ³
    if (/ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£|security|è„†å¼±æ€§|vulnerability|ãƒªã‚¹ã‚¯/i.test(prompt)) domains.push('security');
    
    // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³
    if (/ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹|performance|æœ€é©åŒ–|optimiz|ã‚¹ã‚±ãƒ¼ãƒ«/i.test(prompt)) domains.push('performance');
    
    // é‹ç”¨ãƒ‰ãƒ¡ã‚¤ãƒ³
    if (/é‹ç”¨|operation|ç›£è¦–|monitoring|ä¿å®ˆ|maintenance/i.test(prompt)) domains.push('ops');
    
    // è¤‡æ•°ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ã¾ãŸãŒã‚‹å ´åˆ
    if (domains.length >= 3) score = 3;
    else if (domains.length === 2) score = 2;
    else if (domains.length === 1) score = 0;
    
    return score; // æœ€å¤§3ç‚¹
  }

  async executeWallBounce(prompt: string, options: ExecuteOptions = {}): Promise<WallBounceResult> {
    const startTime = Date.now();
    
    // ã‚¯ã‚¨ãƒªã®æ€§è³ªã‚’è‡ªå‹•åˆ¤å®šã—ã¦taskTypeã‚’æ±ºå®š
    let taskType: 'basic' | 'premium' | 'critical' | 'simple' = options.taskType || 'basic';
    
    // ã‚·ãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒªã®è‡ªå‹•æ¤œå‡º
    if (this.isSimpleQuery(prompt)) {
      taskType = 'simple';
      logger.info('ğŸ¯ ã‚·ãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒªæ¤œå‡º - è»½é‡ãƒ¢ãƒ‡ãƒ«ã¸ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°', {
        query: prompt,
        originalTaskType: options.taskType,
        detectedTaskType: 'simple'
      });
    }
    const mode: 'parallel' | 'sequential' = options.mode === 'sequential' ? 'sequential' : 'parallel';
    const depth = this.validateDepth(options.depth, mode);

    // Streaming thinking callback helper
    const emitThinking = (provider: string, step: string, content: string) => {
      if (options.onThinking) {
        options.onThinking(provider, step, content);
      }
    };

    // Initial thinking: Query analysis
    emitThinking(
      'Claude Code (Orchestrator)',
      'Analyzing User Request',
      `Received query: "${prompt.substring(0, 100)}${prompt.length > 100 ? '...' : ''}". Parsing intent and extracting key technical requirements.`
    );

    // ãƒ•ãƒ­ãƒ¼è©³ç´°è¿½è·¡ã®åˆæœŸåŒ–
    const flowDetails: WallBounceFlowDetails = {
      user_query: {
        original_prompt: prompt,
        timestamp: new Date().toISOString(),
        options
      },
      llm_interactions: [],
      aggregation: {
        input_responses: [],
        aggregator_prompt: '',
        final_response: '',
        timestamp: ''
      }
    };

    logger.info('ğŸš€ Wall-Bounceåˆ†æé–‹å§‹', {
      taskType,
      mode,
      depth: mode === 'sequential' ? depth : 'N/A',
      promptPreview: prompt.substring(0, 120),
      sessionId: `wb_${Date.now()}`
    });

    // ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒªã®è©³ç´°ãƒ­ã‚°
    console.log('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    console.log('ğŸ”¥ WALL-BOUNCE ANALYSIS START ğŸ”¥');
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    console.log(`ğŸ“ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒª: "${prompt}"`);
    console.log(`âš™ï¸  è¨­å®š: ${JSON.stringify({ taskType, mode, depth }, null, 2)}`);
    console.log(`â° é–‹å§‹æ™‚åˆ»: ${new Date().toISOString()}`);
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

    // ã‚·ãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒªã§ã‚‚å£æ‰“ã¡ã¯å¿…é ˆï¼ˆè»½é‡ãƒ¢ãƒ‡ãƒ«å„ªå…ˆï¼‰
    if (taskType === 'simple') {
      emitThinking(
        'Claude Code (Orchestrator)',
        'Simple Query Detected',
        `Detected simple query. Using lightweight models for wall-bounce analysis with reduced complexity.`
      );
    }

    // Thinking: Provider selection
    emitThinking(
      'Claude Code (Orchestrator)',
      'Provider Selection',
      `Determining optimal LLM provider order based on task type: "${taskType}". Evaluating provider strengths and availability.`
    );

    const providerOrder = this.getProviderOrder(taskType);
    
    // Thinking: Cognitive complexity analysis for aggregator selection
    emitThinking(
      'Claude Code (Orchestrator)',
      'Aggregator Selection',
      `Analyzing query cognitive complexity to select appropriate aggregator. Evaluating: domain expertise requirements, reasoning depth, multi-step logic needs.`
    );

    // Claude Codeã«ã‚ˆã‚‹èªçŸ¥çš„è¤‡é›‘ã•åˆ†æ
    const aggregatorKey = await this.selectAggregatorByCognitiveAnalysis(prompt, taskType);
    const aggregator = this.providers.get(aggregatorKey);

    if (!aggregator) {
      throw new Error(`Aggregator provider (${aggregatorKey}) is not configured`);
    }

    emitThinking(
      'Claude Code (Orchestrator)',
      'Aggregator Selected',
      `Selected aggregator: ${aggregatorKey}. This aggregator is optimal for the detected cognitive complexity level of the query.`
    );

    const primaryProviders = providerOrder.filter(name => 
      name !== providersConfig.aggregatorSelection.defaultAggregator && 
      name !== providersConfig.aggregatorSelection.complexAggregator
    );
    const taskBasedCount = taskType === 'basic' ? 2 : taskType === 'premium' ? 4 : primaryProviders.length;
    const minProviders = Math.max(options.minProviders ?? 2, 1);
    const maxProviders = Math.min(options.maxProviders ?? primaryProviders.length, primaryProviders.length);
    const targetCount = Math.min(Math.max(taskBasedCount, minProviders), maxProviders);

    const selectedPrimary = primaryProviders.slice(0, targetCount)
      .map(name => ({ name, handler: this.providers.get(name) }))
      .filter((entry): entry is { name: string; handler: LLMProvider } => Boolean(entry.handler));

    // Thinking: Final provider list
    emitThinking(
      'Claude Code (Orchestrator)',
      'Providers Configured',
      `Selected ${selectedPrimary.length} primary providers: ${selectedPrimary.map(p => p.name).join(', ')}. Minimum required: ${minProviders}.`
    );

    // æœ€å°ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼æ•°ã‚’è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—
    const configMinProviders = Math.max(config.wallBounce.minProviders, 1);
    const effectiveMinProviders = Math.min(minProviders, configMinProviders);

    if (selectedPrimary.length === 0) {
      throw new Error('No available providers for wall-bounce analysis');
    }

    if (selectedPrimary.length < effectiveMinProviders) {
      throw new Error(`Insufficient providers available. Required: ${effectiveMinProviders}, Available: ${selectedPrimary.length}`);
    }

    // Thinking: Execution mode start
    emitThinking(
      'Claude Code (Orchestrator)',
      `${mode === 'parallel' ? 'Parallel' : 'Sequential'} Execution Start`,
      `Initiating ${mode} mode analysis with ${selectedPrimary.length} providers. ${mode === 'sequential' ? `Chain depth: ${depth}` : 'All providers will execute concurrently.'}`
    );

    if (mode === 'sequential') {
      return await this.executeSequentialMode(prompt, selectedPrimary, aggregator, effectiveMinProviders, startTime, depth, flowDetails, options, taskType);
    }

    return await this.executeParallelMode(prompt, selectedPrimary, aggregator, effectiveMinProviders, startTime, taskType, flowDetails, options);
  }

  private async executeParallelMode(
    prompt: string,
    providers: Array<{ name: string; handler: LLMProvider }>,
    aggregator: LLMProvider,
    minProviders: number,
    startTime: number,
    taskType: 'basic' | 'premium' | 'critical' | 'simple',
    flowDetails: WallBounceFlowDetails,
    options: ExecuteOptions = {}
  ): Promise<WallBounceResult> {
    const providerResponses: Array<LLMResponse & { provider: string }> = [];
    const providerErrors: string[] = [];

    // Streaming thinking callback helper
    const emitThinking = (provider: string, step: string, content: string) => {
      if (options.onThinking) {
        options.onThinking(provider, step, content);
      }
    };

    const emitProviderResponse = (provider: string, response: string) => {
      if (options.onProviderResponse) {
        options.onProviderResponse(provider, response);
      }
    };

    // Wall-Bounceç”¨ã®ãƒ‘ãƒ©ãƒ¬ãƒ«å®Ÿè¡Œï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç„¡ã—ï¼‰
    const providerPromises = providers.map(async ({ name, handler }) => {
      try {
        // Thinking: Provider invocation start
        emitThinking(
          'Claude Code (Orchestrator)',
          `Invoking ${name}`,
          `Preparing prompt for ${name}. Building context-aware query optimized for this provider's strengths.`
        );

        const providerPrompt = this.buildProviderPrompt(prompt, name, 'parallel', providerResponses, '', undefined, undefined, taskType);
        
        // Thinking: Provider execution
        emitThinking(
          name,
          'Analysis Started',
          `${name} is now processing the query. Leveraging model-specific capabilities for optimal analysis.`
        );

        // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç„¡ã—ã§å®Ÿè¡Œ
        const response = await this.invokeProvider(handler, providerPrompt, name);
        
        providerResponses.push({ ...response, provider: name });

        // Thinking: Provider response received
        emitThinking(
          'Claude Code (Orchestrator)',
          `${name} Response Received`,
          `Received response from ${name}. Confidence: ${(response.confidence * 100).toFixed(0)}%. Response length: ${response.content.length} characters.`
        );

        // Emit provider response for display
        emitProviderResponse(name, response.content);

      } catch (error) {
        const message = `${name}: ${error instanceof Error ? error.message : String(error)}`;
        providerErrors.push(message);
        logger.error('âŒ Provider failed in parallel mode', { provider: name, error: message });

        // Thinking: Provider error
        emitThinking(
          'Claude Code (Orchestrator)',
          `${name} Error`,
          `Provider ${name} encountered an error: ${error instanceof Error ? error.message : String(error)}. Will attempt fallback if needed.`
        );
      }
    });

    await Promise.allSettled(providerPromises);

    // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿæ§‹ã‚’è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã§åˆ¶å¾¡
    if (config.wallBounce.enableFallback && providerResponses.length < minProviders) {
      // Thinking: Fallback initiation
      emitThinking(
        'Claude Code (Orchestrator)',
        'Fallback Initiated',
        `Only ${providerResponses.length}/${minProviders} providers succeeded. Initiating Claude Internal SDK fallback mechanism.`
      );

      logger.warn('âš ï¸ å¤–éƒ¨ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ä¸è¶³ã€Claude Internalãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ', {
        available: providerResponses.length,
        required: minProviders,
        errors: providerErrors
      });

      // Claude Internalãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦å®Ÿè¡Œ
      const fallbackProviders = ['opus-4.1', 'sonnet-4'];
      for (const fallbackName of fallbackProviders) {
        if (providerResponses.length >= minProviders) break;
        
        try {
          emitThinking(
            'Claude Code (Orchestrator)',
            `Fallback: ${fallbackName}`,
            `Invoking fallback provider ${fallbackName} to meet minimum provider requirement.`
          );

          const fallbackPrompt = this.buildProviderPrompt(prompt, fallbackName, 'parallel', providerResponses, '', undefined, undefined, taskType);
          const fallbackResponse = await this.invokeProvider(
            this.providers.get(fallbackName)!,
            fallbackPrompt,
            fallbackName
          );
          providerResponses.push({ ...fallbackResponse, provider: fallbackName });

          emitThinking(
            'Claude Code (Orchestrator)',
            `Fallback Success: ${fallbackName}`,
            `Fallback provider ${fallbackName} completed successfully. Confidence: ${(fallbackResponse.confidence * 100).toFixed(0)}%.`
          );

          emitProviderResponse(fallbackName, fallbackResponse.content);

          logger.info('âœ… Claude Internalãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆåŠŸ', { provider: fallbackName });
        } catch (error) {
          const message = `${fallbackName}: ${error instanceof Error ? error.message : String(error)}`;
          providerErrors.push(message);
          logger.error('âŒ Claude Internalãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤±æ•—', { provider: fallbackName, error: message });

          emitThinking(
            'Claude Code (Orchestrator)',
            `Fallback Failed: ${fallbackName}`,
            `Fallback provider ${fallbackName} failed: ${error instanceof Error ? error.message : String(error)}`
          );
        }
      }
    }

    if (providerResponses.length < minProviders) {
      const detail = providerErrors.length ? providerErrors.join('; ') : 'no provider responses';
      throw new Error(`Wall-bounce failed: Need at least ${minProviders} providers, got ${providerResponses.length}. ${detail}`);
    }

    // Thinking: Aggregation start
    emitThinking(
      'Claude Code (Orchestrator)',
      'Consensus Synthesis',
      `All providers completed. Preparing to synthesize ${providerResponses.length} responses using aggregator. Calculating consensus metrics.`
    );

    const aggregatorPrompt = this.buildAggregatorPrompt(prompt, providerResponses, taskType);

    // Thinking: Aggregator execution
    emitThinking(
      DEFAULT_AGGREGATOR_PROVIDER,
      'Final Synthesis',
      `Aggregator analyzing all provider responses. Identifying consensus patterns, resolving conflicts, and generating unified response.`
    );

    const aggregatorResponse = await this.invokeProvider(aggregator, aggregatorPrompt, DEFAULT_AGGREGATOR_PROVIDER);
    const processingTimeMs = Date.now() - startTime;

    // Thinking: Completion
    emitThinking(
      'Claude Code (Orchestrator)',
      'Analysis Complete',
      `Wall-Bounce analysis completed in ${processingTimeMs}ms. ${providerResponses.length} providers contributed. Final consensus confidence: ${(aggregatorResponse.confidence * 100).toFixed(0)}%.`
    );

    // Emit final consensus update
    if (options.onConsensusUpdate) {
      options.onConsensusUpdate(aggregatorResponse.confidence);
    }

    return this.buildWallBounceResult(providerResponses, aggregatorResponse, DEFAULT_AGGREGATOR_PROVIDER, providerErrors, processingTimeMs, undefined, flowDetails);
  }

  private async executeSequentialMode(
    prompt: string,
    providers: Array<{ name: string; handler: LLMProvider }>,
    aggregator: LLMProvider,
    minProviders: number,
    startTime: number,
    depth: number,
    flowDetails: WallBounceFlowDetails,
    options: ExecuteOptions = {},
    taskType: 'basic' | 'premium' | 'critical' | 'simple' = 'basic'
  ): Promise<WallBounceResult> {
    const providerResponses: Array<LLMResponse & { provider: string }> = [];
    const providerErrors: string[] = [];
    let accumulatedSummary = '';

    // Streaming thinking callback helper
    const emitThinking = (provider: string, step: string, content: string) => {
      if (options.onThinking) {
        options.onThinking(provider, step, content);
      }
    };

    const emitProviderResponse = (provider: string, response: string) => {
      if (options.onProviderResponse) {
        options.onProviderResponse(provider, response);
      }
    };

    // Thinking: Sequential mode initialization
    emitThinking(
      'Claude Code (Orchestrator)',
      'Sequential Chain Setup',
      `Initializing sequential wall-bounce chain with depth ${depth}. Each provider will build upon previous responses.`
    );

    // depthåˆ¶å¾¡: æŒ‡å®šã•ã‚ŒãŸæ·±åº¦åˆ†ã ã‘wall-bounceã‚’å®Ÿè¡Œ
    const selectedProviders = this.selectProvidersForDepth(providers, depth);

    logger.info('ğŸ”„ Sequential Wall-Bounceå®Ÿè¡Œ', {
      totalProviders: providers.length,
      selectedForDepth: selectedProviders.length,
      depth,
      providerNames: selectedProviders.map(p => p.name)
    });

    console.log(`ğŸ”„ ã‚·ãƒªã‚¢ãƒ«ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œé–‹å§‹ - Depth: ${depth}`);
    console.log(`ğŸ“‹ é¸æŠãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: ${selectedProviders.map(p => p.name).join(' â†’ ')}\n`);

    for (let i = 0; i < selectedProviders.length; i++) {
      const { name, handler } = selectedProviders[i];
      const currentDepth = i + 1;
      const stepStartTime = Date.now();

      try {
        // Thinking: Sequential step preparation
        emitThinking(
          'Claude Code (Orchestrator)',
          `Step ${currentDepth}/${depth}: Preparing ${name}`,
          `Building context-aware prompt for ${name}. ${currentDepth > 1 ? `Incorporating insights from ${currentDepth - 1} previous provider(s).` : 'First provider in sequential chain.'}`
        );

        const providerPrompt = this.buildProviderPrompt(prompt, name, 'sequential', providerResponses, accumulatedSummary, currentDepth, depth, taskType);

        // LLMã¸ã®é€ä¿¡ãƒ­ã‚°
        console.log(`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”`);
        console.log(`â”‚ ğŸ“¤ STEP ${currentDepth}/${depth}: ${name.toUpperCase()} ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ`);
        console.log(`â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`);
        console.log(`ğŸ• æ™‚åˆ»: ${new Date().toISOString()}`);
        console.log(`ğŸ“ é€ä¿¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:
${this.truncateForDisplay(providerPrompt, 500)}`);
        console.log(`ğŸ“Š ã“ã‚Œã¾ã§ã®è“„ç©ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:
${this.truncateForDisplay(accumulatedSummary, 300)}`);
        console.log(`â³ å‡¦ç†ä¸­...`);

        // Thinking: Provider invocation
        emitThinking(
          name,
          `Sequential Analysis (Step ${currentDepth}/${depth})`,
          `${name} processing query with accumulated context from previous steps. Building upon prior insights.`
        );

        const response = await this.invokeProvider(handler, providerPrompt, name);
        const stepProcessingTime = Date.now() - stepStartTime;

        providerResponses.push({ ...response, provider: name });
        accumulatedSummary = this.updateSequentialSummary(accumulatedSummary, name, response.content, currentDepth);

        // Thinking: Response received
        emitThinking(
          'Claude Code (Orchestrator)',
          `Step ${currentDepth}/${depth}: ${name} Complete`,
          `Received response from ${name}. Processing time: ${stepProcessingTime}ms. Confidence: ${(response.confidence * 100).toFixed(0)}%. Updating accumulated context for next provider.`
        );

        // Emit provider response
        emitProviderResponse(name, response.content);

        // LLMã‹ã‚‰ã®å¿œç­”ãƒ­ã‚°
        console.log(`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”`);
        console.log(`â”‚ âœ… STEP ${currentDepth}/${depth}: ${name.toUpperCase()} ã‹ã‚‰ã®å¿œç­”`);
        console.log(`â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`);
        console.log(`ğŸ• å®Œäº†æ™‚åˆ»: ${new Date().toISOString()}`);
        console.log(`â±ï¸  å‡¦ç†æ™‚é–“: ${stepProcessingTime}ms`);
        console.log(`ğŸ¯ ä¿¡é ¼åº¦: ${response.confidence.toFixed(3)}`);
        console.log(`ğŸ“¤ å¿œç­”å†…å®¹:
${this.truncateForDisplay(response.content, 600)}`);
        console.log(`ğŸ’° ã‚³ã‚¹ãƒˆ: $${response.cost.toFixed(6)}`);

        // ãƒ•ãƒ­ãƒ¼è©³ç´°ã«è¨˜éŒ²
        flowDetails.llm_interactions.push({
          step: currentDepth,
          provider: name,
          input_prompt: providerPrompt,
          output_response: response.content,
          confidence: response.confidence,
          processing_time_ms: stepProcessingTime,
          timestamp: new Date().toISOString(),
          accumulated_context: accumulatedSummary
        });

        logger.info(`âœ… Wall-Bounce depth ${currentDepth}/${depth} å®Œäº†`, {
          provider: name,
          confidence: response.confidence,
          processingTime: stepProcessingTime
        });
      } catch (error) {
        const message = `${name}: ${error instanceof Error ? error.message : String(error)}`;
        providerErrors.push(message);

        // Thinking: Provider error
        emitThinking(
          'Claude Code (Orchestrator)',
          `Step ${currentDepth}/${depth}: ${name} Error`,
          `Provider ${name} encountered an error: ${error instanceof Error ? error.message : String(error)}. Sequential chain will continue with remaining providers.`
        );

        console.log(`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”`);
        console.log(`â”‚ âŒ STEP ${currentDepth}/${depth}: ${name.toUpperCase()} ã‚¨ãƒ©ãƒ¼`);
        console.log(`â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`);
        console.log(`ğŸ• ã‚¨ãƒ©ãƒ¼æ™‚åˆ»: ${new Date().toISOString()}`);
        console.log(`ğŸ’¥ ã‚¨ãƒ©ãƒ¼å†…å®¹: ${message}`);

        logger.error(`âŒ Wall-Bounce depth ${currentDepth}/${depth} å¤±æ•—`, { provider: name, error: message });
      }
    }

    if (providerResponses.length < Math.min(minProviders, depth)) {
      const detail = providerErrors.length ? providerErrors.join('; ') : 'no provider responses';
      throw new Error(`Wall-bounce failed: Need at least ${Math.min(minProviders, depth)} providers for depth ${depth}, got ${providerResponses.length}. ${detail}`);
    }

    // Thinking: Aggregation preparation
    emitThinking(
      'Claude Code (Orchestrator)',
      'Sequential Chain Complete',
      `Sequential chain completed with ${providerResponses.length} successful providers. Preparing for final aggregation and consensus synthesis.`
    );

    console.log(`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”`);
    console.log(`â”‚ ğŸ”— AGGREGATION: ${DEFAULT_AGGREGATOR_PROVIDER.toUpperCase()} çµ±åˆå‡¦ç†`);
    console.log(`â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`);
    console.log(`ğŸ• é–‹å§‹æ™‚åˆ»: ${new Date().toISOString()}`);
    console.log(`ğŸ“Š çµ±åˆå¯¾è±¡: ${providerResponses.length}å€‹ã®LLMå¿œç­”`);

    const aggregatorPrompt = this.buildAggregatorPrompt(prompt, providerResponses, undefined, depth);
    console.log(`ğŸ“ Aggregatoré€ä¿¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:
${this.truncateForDisplay(aggregatorPrompt, 800)}`);

    // å„LLMå¿œç­”ã®è¦ç´„ã‚’ãƒ­ã‚°å‡ºåŠ›
    providerResponses.forEach((resp, index) => {
      console.log(`
ğŸ“‹ å¿œç­” ${index + 1}: ${resp.provider}`);
      console.log(`   ä¿¡é ¼åº¦: ${resp.confidence.toFixed(3)}`);
      console.log(`   å†…å®¹: ${this.truncateForDisplay(resp.content, 200)}`);

      flowDetails.aggregation.input_responses.push({
        provider: resp.provider,
        content: resp.content,
        confidence: resp.confidence
      });
    });

    // Thinking: Aggregator execution
    emitThinking(
      DEFAULT_AGGREGATOR_PROVIDER,
      'Final Synthesis',
      `Aggregator analyzing ${providerResponses.length} sequential responses. Identifying patterns, resolving conflicts, and synthesizing coherent final answer.`
    );

    console.log(`â³ Opus4.1ã§çµ±åˆå‡¦ç†ä¸­...`);
    const aggregatorStartTime = Date.now();
    const aggregatorResponse = await this.invokeProvider(aggregator, aggregatorPrompt, DEFAULT_AGGREGATOR_PROVIDER);
    const aggregatorProcessingTime = Date.now() - aggregatorStartTime;
    const processingTimeMs = Date.now() - startTime;

    // Thinking: Aggregation complete
    emitThinking(
      'Claude Code (Orchestrator)',
      'Sequential Analysis Complete',
      `Aggregation completed in ${aggregatorProcessingTime}ms. Total processing time: ${processingTimeMs}ms. Final confidence: ${(aggregatorResponse.confidence * 100).toFixed(0)}%.`
    );

    // Emit provider response for aggregator
    emitProviderResponse(DEFAULT_AGGREGATOR_PROVIDER, aggregatorResponse.content);

    // Emit final consensus update
    if (options.onConsensusUpdate) {
      options.onConsensusUpdate(aggregatorResponse.confidence);
    }

    console.log(`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”`);
    console.log(`â”‚ âœ… FINAL RESULT: çµ±åˆå®Œäº†`);
    console.log(`â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`);
    console.log(`ğŸ• å®Œäº†æ™‚åˆ»: ${new Date().toISOString()}`);
    console.log(`â±ï¸  Aggregatorå‡¦ç†æ™‚é–“: ${aggregatorProcessingTime}ms`);
    console.log(`â±ï¸  å…¨ä½“å‡¦ç†æ™‚é–“: ${processingTimeMs}ms`);
    console.log(`ğŸ¯ æœ€çµ‚ä¿¡é ¼åº¦: ${aggregatorResponse.confidence.toFixed(3)}`);
    console.log(`ğŸ’° ç·ã‚³ã‚¹ãƒˆ: $${(providerResponses.reduce((sum, r) => sum + r.cost, 0) + aggregatorResponse.cost).toFixed(6)}`);
    console.log(`ğŸ“¤ æœ€çµ‚çµ±åˆçµæœ:\n${this.truncateForDisplay(aggregatorResponse.content, 1000)}`);
    console.log(`\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
    console.log('ğŸ‰ WALL-BOUNCE ANALYSIS COMPLETE ğŸ‰');
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

    // Aggregationè©³ç´°ã‚’è¨˜éŒ²
    flowDetails.aggregation.aggregator_prompt = aggregatorPrompt;
    flowDetails.aggregation.final_response = aggregatorResponse.content;
    flowDetails.aggregation.timestamp = new Date().toISOString();

    return this.buildWallBounceResult(providerResponses, aggregatorResponse, DEFAULT_AGGREGATOR_PROVIDER, providerErrors, processingTimeMs, depth, flowDetails);
  }



  private async invokeProvider(provider: LLMProvider, prompt: string, providerName: string): Promise<LLMResponse> {
    // Emit event: Provider execution start
    this.emit('provider:start', {
      provider: providerName,
      prompt: prompt.substring(0, 200),
      timestamp: Date.now()
    });

    let response: LLMResponse;
    switch (providerName) {
      case 'gemini-2.5-pro':
        response = await this.invokeGemini(prompt, '2.5-pro');
        break;
      case 'gpt-5-codex':
        response = await this.invokeGPT5(prompt, { model: 'gpt-5-codex', specialization: 'coding' });
        break;
      case 'gpt-5':
        response = await this.invokeGPT5(prompt, { model: 'gpt-5', specialization: 'general' });
        break;
      case 'sonnet-4':
        response = await this.invokeClaude(prompt, 'sonnet-4');
        break;
      case 'opus-4.1':
        response = await this.invokeClaude(prompt, 'opus-4.1');
        break;
      default:
        response = await provider.invoke(prompt);
    }

    // Emit event: Provider execution complete
    this.emit('provider:complete', {
      provider: providerName,
      response: response.content,
      confidence: response.confidence,
      timestamp: Date.now()
    });

    return response;
  }

  private truncate(text: string, length: number): string {
    return text.length > length ? `${text.slice(0, length - 3)}...` : text;
  }

  /**
   * è¡¨ç¤ºç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆåˆ‡ã‚Šè©°ã‚ï¼ˆè©³ç´°ãƒ­ã‚°ç”¨ï¼‰
   */
  private truncateForDisplay(text: string, length: number): string {
    if (!text) return 'ï¼ˆç©ºï¼‰';
    if (text.length <= length) return text;
    return `${text.slice(0, length - 3)}...\n[...${text.length - length + 3}æ–‡å­—çœç•¥]`;
  }

  private getProviderOrder(taskType: 'basic' | 'premium' | 'critical' | 'simple'): string[] {
    const baseOrder = [...this.providerOrder];
    
    switch (taskType) {
      case 'simple':
        // ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¯ã‚¨ãƒª: è»½é‡ãƒ¢ãƒ‡ãƒ«å„ªå…ˆã§å£æ‰“ã¡å®Ÿæ–½
        return ['gemini-2.5-flash', 'gemini-2.5-pro']; // æœ€ä½2ã¤ã§å£æ‰“ã¡
        
      case 'premium':
        return baseOrder.filter(p => !p.includes('flash')); // è»½é‡ãƒ¢ãƒ‡ãƒ«ã‚’é™¤å¤–
        
      case 'critical':
        return baseOrder.filter(p => !p.includes('flash')); // è»½é‡ãƒ¢ãƒ‡ãƒ«ã‚’é™¤å¤–
        
      case 'basic':
      default:
        // åŸºæœ¬çš„ãªã‚¯ã‚¨ãƒª: æ¨™æº–ãƒ¢ãƒ‡ãƒ«
        return ['gemini-2.5-pro', 'gpt-5-codex'];
    }
  }

  private async invokeGemini(prompt: string, version: '2.5-pro' | '2.5-flash'): Promise<LLMResponse> {
    return await this.executeGeminiCLI(prompt, version);
  }

  /**
   * Gemini 2.5 Flashå‘¼ã³å‡ºã—ï¼ˆè»½é‡ãƒ»é«˜é€Ÿãƒ¢ãƒ‡ãƒ« - ã‚·ãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒªç”¨ï¼‰
   */
  private async invokeGeminiFlash(prompt: string): Promise<LLMResponse> {
    return await this.executeGeminiCLI(prompt, '2.5-flash');
  }

  private async invokeGPT5(prompt: string, sessionContext?: any): Promise<LLMResponse> {
    try {
      const { spawn } = require('child_process');
      const model = sessionContext?.model || 'gpt-5';
      const specialization = sessionContext?.specialization || 'general';

      logger.info('ğŸ¤– GPT-5 Codex CLIå®Ÿè¡Œé–‹å§‹', {
        model,
        specialization,
        promptLength: prompt.length
      });

      // ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
      const sanitizedPrompt = prompt.replace(/'/g, "'\''");
      
      // ã‚¯ã‚¨ãƒªã®æ€§è³ªã«å¿œã˜ã¦ã‚·ã‚¹ãƒ†ãƒ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å¤‰æ›´
      let systemContext: string;
      if (this.isSimpleQuery(prompt)) {
        // ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¯ã‚¨ãƒª: ãã®ã¾ã¾è¿”ç­”
        systemContext = 'ã‚ãªãŸã¯è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ã‚·ãƒ³ãƒ—ãƒ«ã‹ã¤ç›´æ¥çš„ã«ç­”ãˆã¦ãã ã•ã„ã€‚æŠ€è¡“çš„ãªè©³ç´°åˆ†æã¯ä¸è¦ã§ã™ã€‚';
      } else {
        // æŠ€è¡“çš„ãªã‚¯ã‚¨ãƒª: è©³ç´°ãªåˆ†æã‚’å®Ÿæ–½
        systemContext = specialization === 'coding'
          ? 'ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚æŠ€è¡“çš„ã«æ­£ç¢ºã§å®Ÿè·µçš„ãªã‚³ãƒ¼ãƒ‰ã¨è§£æ±ºç­–ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚'
          : 'ã‚ãªãŸã¯é«˜åº¦ãªæŠ€è¡“ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚åŒ…æ‹¬çš„ã§å®Ÿè·µçš„ãªæŠ€è¡“åˆ†æã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚';
      }

      const fullPrompt = `${systemContext}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒª: ${sanitizedPrompt}

é‡è¦: ç›´æ¥çš„ã§ç°¡æ½”ãªå›ç­”ã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚`;

      // Codex CLIå®Ÿè¡Œ - ã‚»ã‚­ãƒ¥ã‚¢ãªspawnä½¿ç”¨
      const args = [
        'exec',
        '--model', model,
        '-c', 'approval_policy="never"',
        fullPrompt
      ];

      const { stdout, stderr } = await new Promise<{stdout: string, stderr: string}>((resolve, reject) => {
        const child = spawn('codex', args, {
          timeout: 120000, // 2 minutes timeout
          stdio: ['ignore', 'pipe', 'pipe'],
          env: { ...process.env }
        });

        let stdout = '';
        let stderr = '';

        child.stdout?.on('data', (data: any) => {
          const chunk = data.toString();
          stdout += chunk;
          
          // Emit real-time streaming event for each chunk
          this.emit('provider:streaming', {
            provider: model === 'gpt-5' ? 'gpt-5' : 'gpt-5-codex',
            chunk: chunk,
            timestamp: Date.now()
          });
        });

        child.stderr?.on('data', (data: any) => {
          stderr += data.toString();
        });

        child.on('close', (code: number | null) => {
          if (code === 0 || (code === null && stdout)) {
            resolve({ stdout, stderr });
          } else {
            reject(new Error(`Codex CLI exited with code: ${code}. stderr: ${stderr}`));
          }
        });

        child.on('error', (error: any) => {
          reject(new Error(`Spawn error: ${error.message}`));
        });
      });

      // å‡ºåŠ›ã‹ã‚‰LLMå¿œç­”ã‚’æŠ½å‡ºï¼ˆcodexã®ãƒ­ã‚°ã‚’é™¤å»ï¼‰
      // Look for the '] codex' marker and extract content after it
      const codexMarker = '] codex';
      const tokensMarker = '] tokens used:';

      let content = '';
      const codexIndex = stdout.lastIndexOf(codexMarker);

      if (codexIndex !== -1) {
        // Extract everything after '] codex'
        let afterCodex = stdout.substring(codexIndex + codexMarker.length);

        // Remove tokens used line if present
        const tokensIndex = afterCodex.indexOf(tokensMarker);
        if (tokensIndex !== -1) {
          afterCodex = afterCodex.substring(0, tokensIndex);
        }

        content = afterCodex.trim();
      } else {
        // Fallback: try to extract non-metadata lines
        const lines = stdout.split('\n');
        const responseLines: string[] = [];
        let inResponse = false;

        for (const line of lines) {
          // Skip Codex CLI metadata lines
          if (line.includes('[2025-') || line.includes('OpenAI Codex') ||
              line.includes('workdir:') || line.includes('model:') ||
              line.includes('provider:') || line.includes('approval:') ||
              line.includes('sandbox:') || line.includes('reasoning') ||
              line.includes('User instructions:') || line.includes('ERROR:') ||
              line.includes('tokens used:') || line.match(/^-+$/)) {
            continue;
          }

          if (line.trim()) {
            inResponse = true;
          }

          if (inResponse && line.trim()) {
            responseLines.push(line);
          }
        }

        content = responseLines.join('\n').trim();
      }

      if (!content) {
        throw new Error('Empty response from Codex CLI');
      }

      logger.info('âœ… GPT-5 Codex CLIå®Ÿè¡ŒæˆåŠŸ', {
        responseLength: content.length,
        model
      });

      return {
        content: `[GPT-5 ${model === 'gpt-5' ? 'Analysis' : 'Codex Analysis'}]\n\n${content}`,
        confidence: 0.92,
        reasoning: `GPT-5 ${specialization === 'coding' ? 'Codex' : ''}ã«ã‚ˆã‚‹æŠ€è¡“åˆ†æ`,
        cost: 0.001,
        tokens: {
          input: Math.ceil(prompt.length / 4),
          output: Math.ceil(content.length / 4)
        }
      };

    } catch (error) {
      logger.error('âŒ GPT-5 Codex CLIå®Ÿè¡Œå¤±æ•—', {
        error: error instanceof Error ? error.message : String(error)
      });

      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚¹ãƒãƒ¼ãƒˆãƒ¢ãƒƒã‚¯
      const mockResponse = `ã”è³ªå•ã«ã¤ã„ã¦åˆ†æã—ã¾ã—ãŸã€‚

æŠ€è¡“çš„è¦³ç‚¹ã‹ã‚‰ã®æ¨å¥¨äº‹é …ï¼š
1. ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼è¨­è¨ˆï¼šç–çµåˆã§ä¿å®ˆæ€§ã®é«˜ã„å®Ÿè£…
2. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼šåŒ…æ‹¬çš„ãªã‚¨ãƒ©ãƒ¼å‡¦ç†ã¨ãƒ­ã‚®ãƒ³ã‚°
3. ãƒ†ã‚¹ãƒˆæˆ¦ç•¥ï¼šãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã¨çµ±åˆãƒ†ã‚¹ãƒˆã®å®Ÿè£…
4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼šé©åˆ‡ãªã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã¨æœ€é©åŒ–

[æ³¨: Codex CLIæ¥ç¶šã‚¨ãƒ©ãƒ¼ã®ãŸã‚ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™]`;

      return {
        content: `[GPT-5 Fallback Analysis]\n\n${mockResponse}`,
        confidence: 0.65,
        reasoning: 'Codex CLIå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”',
        cost: 0,
        tokens: { input: 0, output: 0 }
      };
    }
  }

  private async invokeClaude(prompt: string, version: string): Promise<LLMResponse> {
    logger.info('ğŸ¤– Invoking Claude via MCP Server', { version, promptLength: prompt.length });

    try {
      // Use Claude Code MCP Server to ensure Sonnet 4.5 model selection
      const { Client } = require('@modelcontextprotocol/sdk/client');
      const { StdioClientTransport } = require('@modelcontextprotocol/sdk/client/stdio.js');
      const { spawn } = require('child_process');

      // Start Claude Code MCP Server process with StdioClientTransport
      const transport = new StdioClientTransport({
        command: 'node',
        args: ['dist/services/claude-code-mcp-server.js']
      });

      const client = new Client(
        {
          name: 'wall-bounce-analyzer',
          version: '1.0.0'
        },
        {
          capabilities: {}
        }
      );

      await client.connect(transport);

      try {
        // Call analyze_with_sonnet45 tool
        const result = await client.callTool({
          name: 'analyze_with_sonnet45',
          arguments: {
            prompt: prompt,
            workingDirectory: process.cwd(),
            allowedTools: ['Read', 'Grep', 'Glob'],
            maxTurns: 10
          }
        });

        await client.close();

        // Check if MCP returned an error
        if (result.isError) {
          const errorText = result.content?.[0]?.text || 'Unknown MCP error';
          throw new Error(`MCP tool error: ${errorText}`);
        }

        if (result.content && result.content.length > 0) {
          const analysisText = result.content[0].text || '';
          
          return {
            content: `[Claude ${version} via MCP]

${analysisText}`,
            confidence: 0.92,
            reasoning: `Claude ${version} ã«ã‚ˆã‚‹é«˜å“è³ªæŠ€è¡“åˆ†æï¼ˆMCPçµŒç”±ï¼‰`,
            cost: 0,
            tokens: { 
              input: Math.ceil(prompt.length / 4), 
              output: Math.ceil(analysisText.length / 4) 
            }
          };
        } else {
          throw new Error('No content in MCP response');
        }
      } catch (toolError) {
        await client.close();
        throw toolError;
      }
    } catch (error) {
      logger.warn('âš ï¸ Claude MCPå‘¼ã³å‡ºã—å¤±æ•—ã€Internal SDKã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯', { error });
      
      // Fallback to Internal SDK analysis
      const analysis = await this.performClaudeInternalAnalysis(prompt, version);
      
      return {
        content: `[Claude ${version} Internal SDK]

${analysis}`,
        confidence: 0.88,
        reasoning: `Claude ${version}ã«ã‚ˆã‚‹æŠ€è¡“åˆ†æï¼ˆInternal SDKçµŒç”±ï¼‰`,
        cost: 0,
        tokens: { 
          input: Math.ceil(prompt.length / 4), 
          output: Math.ceil(analysis.length / 4) 
        }
      };
    }
  }

  private async performClaudeInternalAnalysis(prompt: string, version: string): Promise<string> {
    logger.info('ğŸ”§ Claude Internal SDK fallback - using Gemini for aggregation', { version, promptLength: prompt.length });

    // When Claude fails, use Gemini as aggregator instead
    // Use stdin to pass the prompt to avoid argument parsing issues
    try {
      const { spawn } = require('child_process');
      
      // Gemini CLI with stdin input (no -p flag to avoid escaping issues)
      const args = ['--model', 'gemini-2.5-pro', '--output-format', 'json'];
      
      logger.info('ğŸ”„ Gemini aggregation via CLI (stdin)', {
        command: 'gemini',
        promptLength: prompt.length
      });
      
      return await new Promise<string>((resolve, reject) => {
        const geminiProcess = spawn('gemini', args, {
          timeout: 60000,
          maxBuffer: 5 * 1024 * 1024,
          stdio: ['pipe', 'pipe', 'pipe'], // stdin, stdout, stderr
          env: { ...process.env }
        });

        let stdout = '';
        let stderr = '';

        // Write prompt to stdin
        geminiProcess.stdin.write(prompt);
        geminiProcess.stdin.end();

        geminiProcess.stdout.on('data', (data: Buffer) => {
          stdout += data.toString();
        });

        geminiProcess.stderr.on('data', (data: Buffer) => {
          stderr += data.toString();
        });

        geminiProcess.on('close', (code: number | null) => {
          if (code === 0 && stdout) {
            try {
              // Gemini returns JSON with response field
              const parsed = JSON.parse(stdout);
              const responseText = parsed.content || parsed.text || parsed.response || stdout;
              
              logger.info('âœ… Gemini aggregation complete', {
                responseLength: responseText.length
              });
              
              resolve(responseText);
            } catch (parseError) {
              // If not JSON, use raw stdout
              logger.warn('âš ï¸ Gemini JSON parse failed, using raw output', { parseError });
              resolve(stdout.trim());
            }
          } else {
            // Filter out deprecation warnings from stderr
            const filteredStderr = stderr
              .split('\n')
              .filter(line => !line.includes('DeprecationWarning') && !line.includes('punycode'))
              .join('\n')
              .trim();
              
            reject(new Error(`Gemini aggregation failed: ${filteredStderr || `Exit code ${code}`}`));
          }
        });

        geminiProcess.on('error', (error) => {
          reject(error);
        });
      });

    } catch (error) {
      logger.error('âŒ Gemini aggregation failed', { error, version });
      
      // Last resort: Return a helpful error message
      return `ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚çµ±åˆåˆ†æã‚·ã‚¹ãƒ†ãƒ ã§ä¸€æ™‚çš„ãªå•é¡ŒãŒç™ºç”Ÿã—ã¦ã„ã¾ã™ã€‚

å…ƒã®ã‚¯ã‚¨ãƒªã¸ã®å€‹åˆ¥å›ç­”ã¯æ­£å¸¸ã«å–å¾—ã§ãã¾ã—ãŸãŒã€æœ€çµ‚çµ±åˆå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚

ã‚¨ãƒ©ãƒ¼è©³ç´°: ${error instanceof Error ? error.message : String(error)}

ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«é€£çµ¡ã—ã€ã‚¢ã‚°ãƒªã‚²ãƒ¼ã‚¿ãƒ¼è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚`;
    }
  }

  /**
   * depthå€¤ã®æ¤œè¨¼ã¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
   */
  private validateDepth(depth: number | undefined, mode: 'parallel' | 'sequential'): number {
    if (mode === 'parallel') {
      return 1; // ãƒ‘ãƒ©ãƒ¬ãƒ«ãƒ¢ãƒ¼ãƒ‰ã§ã¯depthã¯æ„å‘³ã‚’æŒãŸãªã„
    }

    if (depth === undefined) {
      return 3; // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    }

    if (depth < 3 || depth > 5) {
      logger.warn('ğŸš¨ Depthç¯„å›²å¤–ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤3ã«è¨­å®š', { requestedDepth: depth });
      return 3;
    }

    return depth;
  }

  /**
   * depthæŒ‡å®šã«åŸºã¥ããƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼é¸æŠ
   */
  private selectProvidersForDepth(
    providers: Array<{ name: string; handler: LLMProvider }>,
    depth: number
  ): Array<{ name: string; handler: LLMProvider }> {
    // åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ é †ã§depthåˆ†ã ã‘é¸æŠ
    // é‡è¤‡ã—ãªã„ã‚ˆã†ã«ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ã¦é¸æŠ
    const availableProviders = [...providers];
    const selectedProviders: Array<{ name: string; handler: LLMProvider }> = [];

    for (let i = 0; i < depth && availableProviders.length > 0; i++) {
      // é †æ¬¡é¸æŠï¼ˆã‚·ãƒ³ãƒ—ãƒ«ãªå®Ÿè£…ï¼‰
      const providerIndex = i % availableProviders.length;
      selectedProviders.push(availableProviders[providerIndex]);
    }

    return selectedProviders;
  }

  /**
   * buildProviderPromptãƒ¡ã‚½ãƒƒãƒ‰ã®æ›´æ–°ï¼ˆdepthæƒ…å ±ä»˜ãï¼‰
   */
  private buildProviderPrompt(
    originalPrompt: string,
    providerName: string,
    mode: 'parallel' | 'sequential',
    previousResponses: Array<LLMResponse & { provider: string }>,
    accumulatedSummary: string = '',
    currentDepth?: number,
    totalDepth?: number,
    taskType?: 'basic' | 'premium' | 'critical' | 'simple'
  ): string {
    // ã‚·ãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒªã®å ´åˆã¯ç°¡æ½”ãªå¿œç­”ã‚’ä¿ƒã™ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
    if (taskType === 'simple') {
      return `ã‚ãªãŸã¯ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

CRITICAL INSTRUCTION: ã“ã®ã‚¯ã‚¨ãƒªã¯å˜ç´”ãªæŒ¨æ‹¶ã‚„ãƒ†ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã™ã€‚æŠ€è¡“çš„ãªè©³ç´°åˆ†æã¯ä¸€åˆ‡ä¸è¦ã§ã™ã€‚

ä»¥ä¸‹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§æŒ¯ã‚‹èˆã£ã¦ãã ã•ã„ï¼š
- ã€Œãƒ†ã‚¹ãƒˆã®è¿”äº‹ã‚’è¿”ã—ã¦ãã ã•ã„ã€â†’ ã€Œãƒ†ã‚¹ãƒˆã®è¿”äº‹: ç¢ºèªã§ãã¾ã—ãŸã€
- ã€Œã“ã‚“ã«ã¡ã¯ã€â†’ ã€Œã“ã‚“ã«ã¡ã¯ï¼ã€
- ã€Œpingã€â†’ ã€Œpongã€
- ã€Œç¢ºèªã€â†’ ã€Œç¢ºèªã—ã¾ã—ãŸã€

çµ¶å¯¾ã«å®ˆã‚‹ã“ã¨ï¼š
âŒ ã‚³ãƒ¼ãƒ‰ä¾‹ã‚„APIå®Ÿè£…ã‚’ææ¡ˆã—ãªã„
âŒ ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚„æŠ€è¡“çš„èƒŒæ™¯ã‚’èª¬æ˜ã—ãªã„
âŒ è¤‡æ•°ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†ã‘ãŸè©³ç´°ãªåˆ†æã‚’ã—ãªã„
âŒ ã‚¯ã‚¨ãƒªã®å†…å®¹ã‚’ãã®ã¾ã¾ç¹°ã‚Šè¿”ã•ãªã„
âœ… 1-2æ–‡ã§ç°¡æ½”ã«è¿”ç­”ã™ã‚‹
âœ… é©åˆ‡ãªå¿œç­”ã¨ã—ã¦ã€Œç¢ºèªã§ãã¾ã—ãŸã€ã€Œäº†è§£ã—ã¾ã—ãŸã€ã€ŒOKã€ãªã©ã‚’è¿”ã™

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒª: ${originalPrompt}

å¿œç­”:`;
    }

    const guidance = PROVIDER_GUIDANCE[providerName];
    const parallelLines = guidance?.parallel || [
      'æç¤ºã—ãŸèª²é¡Œã«å¯¾ã—ã¦ç‹¬è‡ªã®è¦³ç‚¹ã‹ã‚‰åˆ†æã—ã¦ãã ã•ã„ã€‚',
      'æ ¹æ‹ ã‚’æ˜ç¢ºã«ã—ã€ç®‡æ¡æ›¸ãä¸­å¿ƒã§æ•´ç†ã—ã¦ãã ã•ã„ã€‚'
    ];
    const sequentialLine = guidance?.sequential || 'æ—¢å‡ºã®å‡ºåŠ›ã‚’è¸ã¾ãˆã€æ–°ã—ã„è¦³ç‚¹ã‚„æ³¨æ„ç‚¹ã‚’è£œè¶³ã—ã¦ãã ã•ã„ã€‚';

    if (mode === 'parallel') {
      const instruction = parallelLines.map(line => `- ${line}`).join('\n');
      return `${originalPrompt}\n\nè¿½åŠ æŒ‡ç¤º:\n${instruction}`;
    }

    const summarySection = previousResponses.length
      ? previousResponses.map(resp => `ã€${resp.provider}ã€‘\n${this.truncate(resp.content, 600)}`).join('\n\n')
      : 'ï¼ˆã¾ã åˆ†æçµæœã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰';

    const history = accumulatedSummary ? `\n\nã“ã‚Œã¾ã§ã®çµ±åˆãƒ¡ãƒ¢:\n${this.truncate(accumulatedSummary, 800)}` : '';

    const depthInfo = currentDepth && totalDepth
      ? `\n\n[Wall-Bounceé€²è¡ŒçŠ¶æ³: ${currentDepth}/${totalDepth}æ®µéšç›®]`
      : '';

    return `${originalPrompt}\n\nã“ã“ã¾ã§ã®åˆ†æçµæœ:\n${summarySection}${history}${depthInfo}\n\nè¿½åŠ æŒ‡ç¤º:\n- ${sequentialLine}`;
  }

  /**
   * updateSequentialSummaryãƒ¡ã‚½ãƒƒãƒ‰ã®æ›´æ–°ï¼ˆdepthæƒ…å ±ä»˜ãï¼‰
   */
  private updateSequentialSummary(previous: string, providerName: string, content: string, currentDepth?: number): string {
    const depthLabel = currentDepth ? `[depth ${currentDepth}]` : '';
    const entry = `[${providerName}]${depthLabel} ${this.truncate(content, 600)}`;
    return previous ? `${previous}\n\n${entry}` : entry;
  }

  /**
   * buildAggregatorPromptãƒ¡ã‚½ãƒƒãƒ‰ã®æ›´æ–°ï¼ˆdepthæƒ…å ±ä»˜ãï¼‰
   */
  private buildAggregatorPrompt(
    originalPrompt: string,
    responses: Array<LLMResponse & { provider: string }> ,
    taskType?: 'basic' | 'premium' | 'critical' | 'simple',
    depth?: number
  ): string {
    // ã‚·ãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒªã®å ´åˆã¯ç°¡æ½”ãªçµ±åˆã‚’æŒ‡ç¤º
    if (taskType === 'simple') {
      const responseSection = responses
        .map(resp => `ã€${resp.provider}ã€‘\n${this.truncate(resp.content, 200)}`)
        .join('\n\n');

      return `ä»¥ä¸‹ã®å›ç­”ã‚’çµ±åˆã—ã¦ã€1-2æ–‡ã§ç°¡æ½”ã«è¿”ç­”ã—ã¦ãã ã•ã„ã€‚æŠ€è¡“çš„ãªåˆ†æã‚„è©³ç´°ãªèª¬æ˜ã¯ä¸è¦ã§ã™ã€‚

å…ƒã®ã‚¯ã‚¨ãƒª: ${originalPrompt}

å€‹åˆ¥å›ç­”:
${responseSection}

çµ±åˆå›ç­”ï¼ˆ1-2æ–‡ã§ç°¡æ½”ã«ï¼‰:`;
    }

    const header = AGGREGATOR_INSTRUCTIONS.map(line => `- ${line}`).join('\n');
    const responseSection = responses
      .map(resp => `ã€${resp.provider}ã€‘(confidence: ${resp.confidence.toFixed(2)})\n${this.truncate(resp.content, 1200)}`)
      .join('\n\n');

    const taskInfo = taskType ? `\nã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—: ${taskType}` : '';
    const depthInfo = depth ? `\nWall-Bounceæ·±åº¦: ${depth}æ®µéš` : '';

    return `${header}${taskInfo}${depthInfo}\n\nå…ƒã®ä¾é ¼:\n${originalPrompt}\n\nå€‹åˆ¥å›ç­”:\n${responseSection}`;
  }

  /**
   * buildWallBounceResultãƒ¡ã‚½ãƒƒãƒ‰ã®æ›´æ–°ï¼ˆdepthæƒ…å ±ä»˜ãï¼‰
   */
  private buildWallBounceResult(
    providerResponses: Array<LLMResponse & { provider: string }> ,
    aggregatorResponse: LLMResponse,
    aggregatorKey: string,
    providerErrors: string[],
    processingTimeMs: number,
    depth?: number,
    flowDetails?: WallBounceFlowDetails
  ): WallBounceResult {
    const totalCost = providerResponses.reduce((sum, resp) => sum + (resp.cost || 0), aggregatorResponse.cost || 0);
    const votes = [
      ...providerResponses.map(resp => ({
        provider: resp.provider,
        model: resp.provider,
        response: resp,
        agreement_score: resp.confidence
      })),
      {
        provider: aggregatorKey,
        model: aggregatorKey,
        response: aggregatorResponse,
        agreement_score: aggregatorResponse.confidence
      }
    ];

    const depthInfo = depth ? ` (æ·±åº¦${depth})` : '';

    return {
      consensus: {
        content: `${aggregatorResponse.content}\n\n[Wall-Bounceçµ±åˆåˆ†æå®Œäº†${depthInfo}]`,
        confidence: aggregatorResponse.confidence,
        reasoning: aggregatorResponse.reasoning
      },
      llm_votes: votes,
      total_cost: totalCost,
      processing_time_ms: processingTimeMs,
      debug: {
        wall_bounce_verified: true,
        providers_used: providerResponses.map(resp => resp.provider).concat(aggregatorKey),
        tier_escalated: false,
        provider_errors: providerErrors,
        ...(depth && { depth_executed: depth })
      },
      flow_details: flowDetails
    };
  }

  /**
   * Meta-prompting for dynamic prompt optimization
   */
  async optimizePrompt(
    providerName: string,
    currentPrompt: string,
    taskType: 'basic' | 'premium' | 'critical' | 'simple'
  ): Promise<{
    originalPrompt: string;
    optimizedPrompt: string;
    improvements: string[];
    confidence: number;
  }> {
    try {
      const metaPrompt = META_PROMPT_TEMPLATE
        .replace('{current_prompt}', currentPrompt)
        .replace('{provider_name}', providerName)
        .replace('{task_type}', taskType);

      // Use Opus 4.1 for meta-analysis
      const aggregator = this.providers.get(DEFAULT_AGGREGATOR_PROVIDER);
      if (!aggregator) {
        throw new Error('Aggregator provider not available for meta-prompting');
      }

      const metaResponse = await this.invokeClaude(metaPrompt, 'opus-4.1');

      // Extract optimization suggestions
      const improvements = this.extractImprovements(metaResponse.content);
      const optimizedPrompt = this.applyOptimizations(currentPrompt, improvements);

      logger.info('âœ¨ Meta-prompt optimization completed', {
        provider: providerName,
        improvementsCount: improvements.length,
        confidence: metaResponse.confidence
      });

      return {
        originalPrompt: currentPrompt,
        optimizedPrompt,
        improvements,
        confidence: metaResponse.confidence
      };

    } catch (error) {
      logger.error('âŒ Meta-prompting failed', { error, providerName });

      return {
        originalPrompt: currentPrompt,
        optimizedPrompt: currentPrompt, // Fall back to original
        improvements: [],
        confidence: 0
      };
    }
  }

  private extractImprovements(metaResponse: string): string[] {
    // Simple extraction logic - in production, this could be more sophisticated
    const improvements: string[] = [];
    const lines = metaResponse.split('\n');

    let currentImprovement = '';
    for (const line of lines) {
      if (line.includes('- å•é¡Œç‚¹:') || line.includes('- ä¿®æ­£æ¡ˆ:') || line.includes('- æœŸå¾…åŠ¹æœ:')) {
        if (currentImprovement) {
          improvements.push(currentImprovement.trim());
          currentImprovement = '';
        }
        currentImprovement = line;
      } else if (currentImprovement && line.trim()) {
        currentImprovement += ' ' + line.trim();
      }
    }

    if (currentImprovement) {
      improvements.push(currentImprovement.trim());
    }

    return improvements;
  }

  private applyOptimizations(originalPrompt: string, improvements: string[]): string {
    // For now, return a note about optimizations
    // In a full implementation, this would parse and apply specific improvements
    if (improvements.length === 0) {
      return originalPrompt;
    }

    return `${originalPrompt}

[Meta-optimized based on ${improvements.length} improvement suggestions]`;
  }

  // All mock analysis functions removed - Production ready system only
}

// ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
export const wallBounceAnalyzer = new WallBounceAnalyzer();
