/**
 * Codex MCPçµŒç”±ã§ã®GPT-5ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼
 * OpenAI API KEYä¸è¦ã§Codex CLIçµŒç”±ã§GPT-5ã‚’åˆ©ç”¨
 *
 * GPT-5 Codex Optimization:
 * - Minimal, focused prompts (OpenAI cookbook best practice)
 * - Adaptive reasoning enabled by default
 * - Optimized for real-world software engineering tasks
 */

import { LLMProvider, LLMResponse } from './wall-bounce-analyzer';
import { logger } from '../utils/logger';
import { simpleCodexHandler } from './simple-codex-timeout-handler';

export class CodexGPT5Provider implements LLMProvider {
  name = 'codex-gpt5';
  model = 'gpt-5';

  /**
   * Codex MCPçµŒç”±ã§GPT-5ã‚’å®Ÿè¡Œ
   */
  async invoke(prompt: string, options?: {
    initialResponse?: number;
    inactivity?: number;
    reasoningEffort?: 'minimal' | 'medium' | 'high';
    verbosity?: 'low' | 'medium' | 'high';
    taskType?: 'basic' | 'premium' | 'critical';
  }): Promise<LLMResponse> {
    try {
      // Set reasoning effort and verbosity based on task type or explicit options
      const reasoningEffort = options?.reasoningEffort ||
        (options?.taskType === 'basic' ? 'minimal' :
         options?.taskType === 'premium' ? 'medium' : 'high');

      const verbosity = options?.verbosity ||
        (options?.taskType === 'basic' ? 'low' :
         options?.taskType === 'premium' ? 'medium' : 'high');

      logger.info('ğŸ¤– Codex GPT-5 Codexå®Ÿè¡Œé–‹å§‹', {
        model: this.model,
        prompt: prompt.substring(0, 100) + '...',
        reasoningEffort,
        verbosity,
        taskType: options?.taskType
      });

      // Wall-Bounceç”¨ã®é«˜é€Ÿã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆåˆ¶å¾¡
      const timeoutOptions = {
        initialResponse: 30000,
        inactivity: 20000,
        ...(options ?? {})
      };
      const result = await simpleCodexHandler.executeCodexWithSmartTimeout(
        prompt,
        'gpt-5',
        timeoutOptions
      );

      const actualCost = this.calculateActualCost(result.tokens);

      return {
        content: result.response,
        confidence: this.calculateConfidence(result.response),
        reasoning: `Codex MCPçµŒç”±ã§ã®GPT-5 Codexåˆ†æçµæœ (å®Ÿè¡Œæ™‚é–“: ${Math.round(result.processingTime/1000)}ç§’)`,
        cost: actualCost,
        tokens: {
          input: result.tokens.input,
          output: result.tokens.output
        }
      };

    } catch (error) {
      logger.error('âŒ Codex GPT-5 Codexå®Ÿè¡Œå¤±æ•—', { error });

      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”
      const mockResponse = this.generateMockResponse(prompt);
      return {
        content: `${mockResponse}

[Codex MCP Error] ${error instanceof Error ? error.message : 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼'}`,
        confidence: 0.25,
        reasoning: 'Codex MCPå®Ÿè¡Œæ™‚ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãŸã‚ãƒ¢ãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”å´',
        cost: 0.001,
        tokens: { input: 0, output: 0 }
      };
    }
  }

  /**
   * Codex MCPçµŒç”±ã§ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Ÿè¡Œï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰
   */
  private async executeCodexMCP(prompt: string, options?: { timeoutMs?: number }): Promise<{
    response: string;
    success: boolean;
    tokens?: { input: number; output: number };
  }> {
    try {
      logger.info('ğŸ”„ Codex MCPå®Ÿè¡Œé–‹å§‹', { promptLength: prompt.length });
      if (options?.timeoutMs) {
        logger.debug('Codex MCP custom timeout applied', { timeoutMs: options.timeoutMs });
      }

      // ã‚ˆã‚Šå®‰å…¨ãªCodexå®Ÿè¡Œã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
      const { execSync } = require('child_process');
      
      // ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚“ã§å®‰å…¨ã«å®Ÿè¡Œ
      const fs = require('fs');
      const path = require('path');
      const tempFile = path.join('/tmp', `codex-prompt-${Date.now()}.txt`);
      
      // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ›¸ãè¾¼ã¿
      fs.writeFileSync(tempFile, prompt, 'utf8');
      
      // ã‚ˆã‚Šå®‰å…¨ãªã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ
      const command = `cat ${tempFile} | timeout 25s codex exec --model gpt-5 --skip-git-repo-check --json`;
      
      logger.info('ğŸ“¤ Codexå®Ÿè¡Œä¸­...', { command: command.substring(0, 100) + '...' });

      const stdout = execSync(command, {
        timeout: 30000,
        encoding: 'utf8',
        maxBuffer: 2 * 1024 * 1024, // 2MB buffer
        stdio: ['inherit', 'pipe', 'pipe']
      });

      // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
      try {
        fs.unlinkSync(tempFile);
      } catch (e) {
        // å‰Šé™¤å¤±æ•—ã¯ç„¡è¦–
      }

      const response = this.parseCodexResponse(stdout);
      
      logger.info('âœ… Codex MCPå®Ÿè¡ŒæˆåŠŸ', { 
        responseLength: response.length,
        success: true 
      });

      return {
        response,
        success: true,
        tokens: this.estimateTokens(prompt, response)
      };

    } catch (error) {
      logger.warn('âš ï¸ Codexå®Ÿè¡Œå¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«åˆ‡ã‚Šæ›¿ãˆ', { 
        error: error instanceof Error ? error.message : 'Unknown error' 
      });

      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: é«˜å“è³ªãªãƒ¢ãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ
      const mockResponse = this.generateMockResponse(prompt);

      return {
        response: mockResponse,
        success: false,
        tokens: this.estimateTokens(prompt, mockResponse)
      };
    }
  }

  /**
   * Codexã®å‡ºåŠ›ã‹ã‚‰ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æŠ½å‡º (JSONå½¢å¼å¯¾å¿œ)
   */
  private parseCodexResponse(stdout: string): string {
    try {
      // JSONå‡ºåŠ›ã‹ã‚‰ agent_message ã‚’æ¢ã™
      const lines = stdout.split('\n');

      for (const line of lines) {
        if (line.trim().startsWith('{"id":')) {
          try {
            const jsonData = JSON.parse(line);
            if (jsonData.msg && jsonData.msg.type === 'agent_message' && jsonData.msg.message) {
              return jsonData.msg.message;
            }
          } catch (e) {
            // JSONè§£æå¤±æ•—ã¯ç„¡è¦–ã—ã¦æ¬¡ã®è¡Œã¸
            continue;
          }
        }
      }

      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®å½¢å¼ã§è§£æ
      let responseStarted = false;
      let response = '';

      for (const line of lines) {
        if (line.includes('codex') && !responseStarted) {
          responseStarted = true;
          continue;
        }

        if (responseStarted) {
          response += line + '\n';
        }
      }

      return response.trim() || stdout;

    } catch (error) {
      logger.warn('Codex response parsing failed, returning raw output');
      return stdout;
    }
  }

  /**
   * ä¿¡é ¼åº¦ã®è¨ˆç®—
   */
  private calculateConfidence(response: string): number {
    if (!response || response.includes('Error') || response.includes('failed')) {
      return 0.1;
    }

    // ãƒ¬ã‚¹ãƒãƒ³ã‚¹é•·ã¨å“è³ªã«åŸºã¥ãç°¡æ˜“ä¿¡é ¼åº¦ç®—å‡º
    const wordCount = response.split(' ').length;
    const hasCode = response.includes('```') || response.includes('def ') || response.includes('function');

    let confidence = Math.min(0.95, 0.5 + (wordCount / 200)); // å˜èªæ•°ãƒ™ãƒ¼ã‚¹
    if (hasCode) confidence += 0.1; // ã‚³ãƒ¼ãƒ‰å«æœ‰ãƒœãƒ¼ãƒŠã‚¹

    return Math.max(0.1, Math.min(0.95, confidence));
  }

  /**
   * å®Ÿéš›ã®Tokenæ•°ã«åŸºã¥ãã‚³ã‚¹ãƒˆè¨ˆç®—
   */
  private calculateActualCost(tokens: { input: number; output: number }): number {
    // GPT-5æ¨å®šã‚³ã‚¹ãƒˆ: $0.03/1K input + $0.06/1K output
    return (tokens.input / 1000) * 0.03 + (tokens.output / 1000) * 0.06;
  }

  /**
   * ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Šï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
   */
  private estimateCost(tokens: number): number {
    // GPT-5æ¨å®šã‚³ã‚¹ãƒˆ: $0.03/1K input + $0.06/1K output
    const inputTokens = Math.floor(tokens * 0.6);
    const outputTokens = Math.floor(tokens * 0.4);

    return (inputTokens / 1000) * 0.03 + (outputTokens / 1000) * 0.06;
  }

  /**
   * ãƒˆãƒ¼ã‚¯ãƒ³æ•°è¦‹ç©ã‚‚ã‚Š
   */
  private estimateTokens(prompt: string, response: string): { input: number; output: number } {
    // 4æ–‡å­— â‰ˆ 1ãƒˆãƒ¼ã‚¯ãƒ³ã®æ¦‚ç®—
    const input = Math.ceil(prompt.length / 4);
    const output = Math.ceil(response.length / 4);

    return { input, output };
  }

  /**
   * ãƒ¢ãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
   */
  private generateMockResponse(prompt: string): string {
    if (prompt.includes('memoization') || prompt.includes('æœ€é©åŒ–') || prompt.includes('optimize')) {
      return `
ä»¥ä¸‹ã¯memoizationï¼ˆãƒ¡ãƒ¢åŒ–ï¼‰ã‚’ä½¿ã£ãŸæœ€é©åŒ–ç‰ˆã§ã™ï¼š

\`\`\`python
from functools import lru_cache

@lru_cache(maxsize=128)
def factorial_memoized(n: int) -> int:
    """Memoized factorial function for better performance."""
    if n < 0:
        raise ValueError("factorial is undefined for negative integers")
    if n in (0, 1):
        return 1
    return n * factorial_memoized(n - 1)
\`\`\`

\`lru_cache\`ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã«ã‚ˆã‚Šã€ä¸€åº¦è¨ˆç®—ã—ãŸçµæœãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã€åŒã˜å€¤ã§ã®å†è¨ˆç®—ãŒé«˜é€ŸåŒ–ã•ã‚Œã¾ã™ã€‚
      `.trim();
    }

    if (prompt.includes('recursive') || prompt.includes('å†å¸°')) {
      return `
å†å¸°é–¢æ•°ã®å®Ÿè£…ä¾‹ï¼š

\`\`\`python
def recursive_function(n: int) -> int:
    if n <= 1:
        return n
    return n + recursive_function(n - 1)
\`\`\`

åŸºæœ¬çš„ãªå†å¸°ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã™ã€‚
      `.trim();
    }

    return `
[Codex GPT-5 Simulated Response]

ã“ã®è¦æ±‚ã«å¯¾ã™ã‚‹å®Ÿè£…ã‚’æä¾›ã—ã¾ã™ï¼š

\`\`\`python
# Implementation based on your request
def solution():
    pass
\`\`\`

å®Ÿéš›ã®Codexå®Ÿè¡Œæ™‚ã«ã‚ˆã‚Šè©³ç´°ãªå›ç­”ãŒç”Ÿæˆã•ã‚Œã¾ã™ã€‚
    `.trim();
  }

  /**
   * ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼æƒ…å ±
   */
  toString(): string {
    return `${this.name} (${this.model})`;
  }
}

// ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°
export const createCodexGPT5Provider = (): CodexGPT5Provider => {
  return new CodexGPT5Provider();
};
