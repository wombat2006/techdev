/**
 * Wall Bounce Orchestrator - Single Responsibility: Coordination & Flow Control
 * å£æ‰“ã¡åˆ†æã®èª¿æ•´ã¨å®Ÿè¡Œãƒ•ãƒ­ãƒ¼åˆ¶å¾¡ã®ã¿ã‚’è²¬ä»»ã¨ã™ã‚‹
 */

import { logger } from '../utils/logger';
import { recordError, recordWallBounceAnalysis } from '../metrics/prometheus-client';
import { LLMProviderRegistry, LLMProvider, TaskType } from './llm-provider-registry';
import { ConsensusEngine, VoteWithScore, ConsensusResult } from './consensus-engine';

export interface WallBounceOptions {
  minProviders?: number;
  maxProviders?: number;
  requireConsensus?: boolean;
  confidenceThreshold?: number;
}

export interface WallBounceResult {
  consensus: ConsensusResult;
  llm_votes: VoteWithScore[];
  total_cost: number;
  processing_time_ms: number;
  debug: {
    wall_bounce_verified: boolean;
    providers_used: string[];
    tier_escalated: boolean;
  };
}

/**
 * å£æ‰“ã¡åˆ†æã®å®Ÿè¡Œèª¿æ•´ã®ã¿ã‚’è²¬ä»»ã¨ã™ã‚‹
 * ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ç®¡ç†ã¯LLMProviderRegistryã€åˆæ„å½¢æˆã¯ConsensusEngineã«å§”è­²
 */
export class WallBounceOrchestrator {
  private providerRegistry: LLMProviderRegistry;
  private consensusEngine: ConsensusEngine;

  constructor() {
    this.providerRegistry = new LLMProviderRegistry();
    this.consensusEngine = new ConsensusEngine();
  }

  /**
   * å£æ‰“ã¡åˆ†æã®ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œãƒ•ãƒ­ãƒ¼
   */
  async analyze(
    prompt: string,
    taskType: TaskType = 'basic',
    options: WallBounceOptions = {}
  ): Promise<WallBounceResult> {
    const startTime = Date.now();
    const {
      minProviders = 2,
      maxProviders = 4,
      requireConsensus = true,
      confidenceThreshold = 0.8
    } = options;

    logger.info('ğŸ”„ Wall-bounce analysis started', {
      taskType,
      minProviders,
      maxProviders,
      promptLength: prompt.length
    });

    try {
      // 1. ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼é¸æŠï¼ˆå§”è­²ï¼‰
      const selectedProviders = this.providerRegistry.getProvidersForTask(taskType, minProviders);

      // 2. ä¸¦åˆ—LLMå®Ÿè¡Œ
      const llmVotes = await this.executeLLMCalls(selectedProviders, prompt);

      // 3. åˆæ„å½¢æˆï¼ˆå§”è­²ï¼‰
      const consensus = await this.consensusEngine.buildConsensus(
        llmVotes,
        requireConsensus,
        confidenceThreshold
      );

      // 4. ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ¤å®š
      const tierEscalated = await this.checkTierEscalation(llmVotes, consensus, taskType);

      // 5. çµæœæ§‹ç¯‰
      const result = this.buildResult(llmVotes, consensus, startTime, tierEscalated);

      // 6. ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
      this.recordMetrics(result, taskType);

      logger.info('âœ… Wall-bounce analysis completed', {
        processingTime: result.processing_time_ms,
        finalConfidence: result.consensus.confidence,
        providersUsed: result.debug.providers_used
      });

      return result;

    } catch (error) {
      const processingTime = Date.now() - startTime;
      logger.error('âŒ Wall-bounce analysis failed', {
        error: error instanceof Error ? error.message : String(error),
        processingTime,
        taskType
      });

      recordError('wall_bounce_analysis_error', 'high', 'wall-bounce-orchestrator');
      throw error;
    }
  }

  /**
   * ä¸¦åˆ—LLMå‘¼ã³å‡ºã—ã®å®Ÿè¡Œ
   */
  private async executeLLMCalls(providers: LLMProvider[], prompt: string): Promise<VoteWithScore[]> {
    const promises = providers.map(async (provider) => {
      const startTime = Date.now();
      try {
        logger.debug(`Calling LLM provider: ${provider.name}`);
        const response = await provider.invoke(prompt, {});

        const processingTime = Date.now() - startTime;
        logger.debug('LLM provider response received', {
          provider: provider.name,
          processingTime
        });

        return {
          provider: provider.name,
          model: provider.model,
          response,
          agreement_score: 0 // ConsensusEngineã§è¨ˆç®—ã•ã‚Œã‚‹
        };

      } catch (error) {
        const processingTime = Date.now() - startTime;
        logger.warn(`LLM provider ${provider.name} failed`, {
          error: error instanceof Error ? error.message : String(error),
          processingTime
        });

        // å¤±æ•—æ™‚ã®ãƒ€ãƒŸãƒ¼å¿œç­”
        return {
          provider: provider.name,
          model: provider.model,
          response: {
            content: `Error: ${provider.name} provider failed`,
            confidence: 0,
            reasoning: `Provider ${provider.name} encountered an error`,
            cost: 0,
            tokens: { input: 0, output: 0 }
          },
          agreement_score: 0
        };
      }
    });

    const results = await Promise.all(promises);
    const successfulResults = results.filter(r => r.response.confidence > 0);

    if (successfulResults.length === 0) {
      throw new Error('All LLM providers failed to respond');
    }

    logger.info('LLM calls completed', {
      totalProviders: providers.length,
      successfulProviders: successfulResults.length,
      failedProviders: providers.length - successfulResults.length
    });

    return successfulResults;
  }

  /**
   * ãƒ†ã‚£ã‚¢ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ¤å®š
   */
  private async checkTierEscalation(
    votes: VoteWithScore[],
    consensus: ConsensusResult,
    taskType: TaskType
  ): Promise<boolean> {
    const qualityEvaluation = this.consensusEngine.evaluateConsensusQuality(votes);

    // å“è³ªãŒä½ã„å ´åˆã¯ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    const shouldEscalate = qualityEvaluation.quality === 'low' &&
                          consensus.confidence < 0.6 &&
                          taskType !== 'critical';

    if (shouldEscalate) {
      logger.info('Tier escalation triggered', {
        currentQuality: qualityEvaluation.quality,
        confidence: consensus.confidence,
        taskType
      });
    }

    return shouldEscalate;
  }

  /**
   * çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®æ§‹ç¯‰
   */
  private buildResult(
    votes: VoteWithScore[],
    consensus: ConsensusResult,
    startTime: number,
    tierEscalated: boolean
  ): WallBounceResult {
    const processingTime = Date.now() - startTime;
    const totalCost = votes.reduce((sum, vote) => sum + vote.response.cost, 0);

    return {
      consensus,
      llm_votes: votes,
      total_cost: totalCost,
      processing_time_ms: processingTime,
      debug: {
        wall_bounce_verified: votes.length >= 2,
        providers_used: votes.map(v => v.provider),
        tier_escalated: tierEscalated
      }
    };
  }

  /**
   * ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
   */
  private recordMetrics(result: WallBounceResult, taskType: TaskType): void {
    recordWallBounceAnalysis(
      taskType,
      result.debug.providers_used,
      result.consensus.confidence,
      result.processing_time_ms,
      result.total_cost,
      'success'
    );
  }

  /**
   * åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ç¢ºèª
   */
  getAvailableProviders(): string[] {
    return this.providerRegistry.getAvailableProviders();
  }

  /**
   * ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å¯ç”¨æ€§ç¢ºèª
   */
  isProviderAvailable(providerName: string): boolean {
    return this.providerRegistry.isProviderAvailable(providerName);
  }
}
